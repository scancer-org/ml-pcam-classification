{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sweep_PCAM_Classification",
      "provenance": [],
      "authorship_tag": "ABX9TyNQ1BpZwA086BPpzebf2jEZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scancer-org/ml-pcam-classification/blob/main/Sweep_PCAM_Classification_For_Hyperparameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VZPNtmNFM_Y"
      },
      "source": [
        "%%capture\n",
        "!pip install -qqq wandb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ovT5NhfFRu7"
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "import wandb\n",
        "import os\n",
        "import pandas as pd\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import time\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from google.colab import drive\n",
        "from torch.utils import data\n",
        "from os import listdir\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from skimage import io, transform\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Model file in models\n",
        "from models.cnn_model import ModelCNN"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhG6tzAeFSzu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9ebaa42b-9e2b-4395-f827-3f193c6b7dd4"
      },
      "source": [
        "wandb.login()\n",
        "wandb.init(project=\"pcam-pytorch-training\")\n",
        "wandb.run.name = \"pcam-pytorch-experiment#-\" + wandb.run.id\n",
        "print(\"Staring experiment: \", wandb.run.name)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdaniel8hen\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.28<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">apricot-butterfly-29</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/daniel8hen/pcam-pytorch-training\" target=\"_blank\">https://wandb.ai/daniel8hen/pcam-pytorch-training</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/daniel8hen/pcam-pytorch-training/runs/3ra9is3s\" target=\"_blank\">https://wandb.ai/daniel8hen/pcam-pytorch-training/runs/3ra9is3s</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210429_141053-3ra9is3s</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Staring experiment:  pcam-pytorch-experiment#-3ra9is3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7Xj0dVGFUj9",
        "outputId": "1fcc1e57-5972-4cba-fa59-52be2ccdfeea"
      },
      "source": [
        "drive.mount('/content/gdrive/')\n",
        "!ls gdrive/MyDrive/pcamv1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "camelyonpatch_level_2_split_test_meta.csv\n",
            "camelyonpatch_level_2_split_test_x.h5\n",
            "camelyonpatch_level_2_split_test_y.h5\n",
            "camelyonpatch_level_2_split_train_mask.h5\n",
            "camelyonpatch_level_2_split_train_meta.csv\n",
            "camelyonpatch_level_2_split_train_x.h5\n",
            "camelyonpatch_level_2_split_train_y.h5\n",
            "camelyonpatch_level_2_split_valid_meta.csv\n",
            "camelyonpatch_level_2_split_valid_x.h5\n",
            "camelyonpatch_level_2_split_valid_y.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7umvRXBMF2WU"
      },
      "source": [
        "### Sweep\n",
        "sweep_config = {\n",
        "    'method': 'bayes'\n",
        "    }\n",
        "\n",
        "metric = {\n",
        "    'name': 'accuracy',\n",
        "    'goal': 'maximize'   \n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "\n",
        "parameters_dict = {\n",
        "    'optimizer': {\n",
        "        'values': ['adam', 'sgd']\n",
        "        },\n",
        "    'dropout': {\n",
        "          'values': [0.3, 0.4, 0.5, 0.6]\n",
        "        },\n",
        "    }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "\n",
        "\n",
        "\n",
        "parameters_dict.update({\n",
        "    'learning_rate': {\n",
        "        # a flat distribution between 0 and 0.2\n",
        "        'distribution': 'uniform',\n",
        "        'min': 0,\n",
        "        'max': 0.2\n",
        "      }\n",
        "})"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7fpg6AIF7Iy",
        "outputId": "3a604487-60d7-4a5a-ce68-2d0f4ddc2bd0"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"pcam_classification-sweeps\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: u8j2z8ff\n",
            "Sweep URL: https://wandb.ai/daniel8hen/pcam_classification-sweeps/sweeps/u8j2z8ff\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDFEaoL16AQc"
      },
      "source": [
        "class H5Dataset(Dataset):\n",
        "    def __init__(self, path, transform=None):\n",
        "        self.file_path = path\n",
        "        self.dataset_x = None\n",
        "        self.dataset_y = None\n",
        "        self.transform = transform\n",
        "        ### Reading X part of HDF5\n",
        "        with h5py.File(self.file_path + '_x.h5', 'r') as filex:\n",
        "            self.dataset_x_len = len(filex['x'])\n",
        "\n",
        "        ### Reading Y part of HDF5\n",
        "        with h5py.File(self.file_path + '_y.h5', 'r') as filey:\n",
        "            self.dataset_y_len = len(filey['y'])\n",
        "\n",
        "    def __len__(self):\n",
        "        assert self.dataset_x_len == self.dataset_y_len # Since we are reading from different sources, validating we are good in terms of size both X, Y\n",
        "        return self.dataset_x_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        imgs_path = self.file_path + '_x.h5'\n",
        "        labels_path = self.file_path + '_y.h5'\n",
        "\n",
        "        if self.dataset_x is None:\n",
        "            self.dataset_x = h5py.File(imgs_path, 'r')['x']\n",
        "        if self.dataset_y is None:\n",
        "            self.dataset_y = h5py.File(labels_path, 'r')['y']\n",
        "\n",
        "        # get one pair of X, Y and return them, transform if needed\n",
        "        image = self.dataset_x[index]\n",
        "        label = self.dataset_y[index]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, label)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJXZ2cV-GCrK"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train(config=None):\n",
        "    # Initialize a new wandb run\n",
        "    with wandb.init(config=config):\n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "        config = wandb.config\n",
        "\n",
        "        loader = build_dataset(16)\n",
        "        network = build_network(config.dropout)\n",
        "        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)\n",
        "\n",
        "        for epoch in range(10):\n",
        "            avg_loss = train_epoch(network, loader, optimizer)\n",
        "            wandb.log({\"loss\": avg_loss, \"epoch\": epoch})           "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6lRKlJ-M75I"
      },
      "source": [
        "def build_dataset(batch_size, train=True):\n",
        "    # Base path of mounted dataset in HDF5\n",
        "    drive_base_path = 'gdrive/MyDrive/pcamv1/'\n",
        "    dataloader_params = {'batch_size': batch_size, 'num_workers': 2}\n",
        "    \n",
        "    if train:\n",
        "      path = drive_base_path + 'camelyonpatch_level_2_split_train'\n",
        "      \n",
        "      # transform\n",
        "      transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "      ])\n",
        "\n",
        "    else:\n",
        "      path = drive_base_path + 'camelyonpatch_level_2_split_valid'\n",
        "      \n",
        "      transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "      ])\n",
        "\n",
        "    dataset = H5Dataset(path, transform=transform)\n",
        "      \n",
        "    sub_dataset = torch.utils.data.Subset(dataset, indices=range(0, len(dataset), 5))\n",
        "    loader = torch.utils.data.DataLoader(sub_dataset, **dataloader_params)\n",
        "\n",
        "    return loader\n",
        "\n",
        "\n",
        "def build_network(dropout):\n",
        "    network = ModelCNN(p=dropout)\n",
        "\n",
        "    return network.to(device)\n",
        "        \n",
        "\n",
        "def build_optimizer(network, optimizer, learning_rate):\n",
        "    if optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(network.parameters(),\n",
        "                              lr=learning_rate, momentum=0.9)\n",
        "    elif optimizer == \"adam\":\n",
        "        optimizer = optim.Adam(network.parameters(),\n",
        "                               lr=learning_rate)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def train_epoch(network, loader, optimizer):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    cumu_loss = 0\n",
        "    for _, (data, target) in enumerate(loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # ➡ Forward pass\n",
        "\n",
        "        output = network(data)\n",
        "        # Update target to be the same dimensions as output\n",
        "        target = target.view(output.shape[0], 1).float()\n",
        "        # Get accuracy measurements\n",
        "        # Calculate the batch's loss\n",
        "        loss = criterion(output, target)\n",
        "        cumu_loss += loss.item()\n",
        "\n",
        "        # ⬅ Backward pass + weight update\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        wandb.log({\"batch loss\": loss.item()})\n",
        "\n",
        "    return cumu_loss / len(loader)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XIR4hfPi6KgU",
        "outputId": "f089f066-e116-4b01-9d02-8101d1089377"
      },
      "source": [
        "wandb.agent(sweep_id, train, count=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bcqs1cgw with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00815923771831415\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.28<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">devoted-sweep-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/daniel8hen/pcam_classification-sweeps\" target=\"_blank\">https://wandb.ai/daniel8hen/pcam_classification-sweeps</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/daniel8hen/pcam_classification-sweeps/sweeps/u8j2z8ff\" target=\"_blank\">https://wandb.ai/daniel8hen/pcam_classification-sweeps/sweeps/u8j2z8ff</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/daniel8hen/pcam_classification-sweeps/runs/bcqs1cgw\" target=\"_blank\">https://wandb.ai/daniel8hen/pcam_classification-sweeps/runs/bcqs1cgw</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210429_141246-bcqs1cgw</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}