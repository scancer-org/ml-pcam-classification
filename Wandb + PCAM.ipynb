{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PCAM Dataset preparation (HDF5) + base training (PyTorch)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0YsZ4HHf2fyv4t9TAODU9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scancer-org/data-prep-and-model-train/blob/main/Wandb%20%2B%20PCAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyfzjdpA-y85"
      },
      "source": [
        "### TODO:\n",
        "# Load data - this is the major phase here\n",
        "# Sample out of the data - like 100 examples for train, 20 example for test, same distribution of classes\n",
        "# Have some stats on it\n",
        "# Create (in PyTorch) a base model\n",
        "# Train\n",
        "# Eval\n",
        "# Test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZEMtZprUODk"
      },
      "source": [
        "%%capture\n",
        "!pip install -qqq wandb pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELY-zN5F_DT5"
      },
      "source": [
        "# Test labels (from original, which I'll split for train / test)\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "import wandb\n",
        "import os\n",
        "import pandas as pd\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import time\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from google.colab import drive\n",
        "from torch.utils import data\n",
        "from os import listdir\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from skimage import io, transform\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# anyeone interested should have this path configured already, dataset can be downloaded from GitHub / Drive (PCAM)\n",
        "# Batch Size = 128\n",
        "CHECKPOINT_DIR = 'checkpoint'\n",
        "drive_base_path = 'gdrive/MyDrive/pcamv1/'\n",
        "BATCH_SIZE = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "1vM8kvD3U0gs",
        "outputId": "3f10947a-54a0-4b7a-83a4-b22da49423c1"
      },
      "source": [
        "pl.seed_everything(hash(\"setting random seeds\") % 2**32 -1)\n",
        "\n",
        "# wandblogger <> from pytorch ligthning!\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 3551501822\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "KKZ647BqYL09",
        "outputId": "e80d1d1e-c140-4f88-f0fd-b9b4543b8db4"
      },
      "source": [
        "wandb.init(project=\"pcam-pytorch-training\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdaniel8hen\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.25<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">glowing-firefly-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/daniel8hen/pcam-pytorch-training\" target=\"_blank\">https://wandb.ai/daniel8hen/pcam-pytorch-training</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/daniel8hen/pcam-pytorch-training/runs/2xr2hqyf\" target=\"_blank\">https://wandb.ai/daniel8hen/pcam-pytorch-training/runs/2xr2hqyf</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210407_172832-2xr2hqyf</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f3809ed2e50>"
            ],
            "text/html": [
              "<h1>Run(2xr2hqyf)</h1><iframe src=\"https://wandb.ai/daniel8hen/pcam-pytorch-training/runs/2xr2hqyf\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WsftmTCxxDd",
        "outputId": "a7f3eabb-58ab-461b-fd92-75927fb55961"
      },
      "source": [
        "drive.mount('/content/gdrive/')\n",
        "!ls gdrive/MyDrive/pcamv1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n",
            "camelyonpatch_level_2_split_test_meta.csv\n",
            "camelyonpatch_level_2_split_test_x.h5\n",
            "camelyonpatch_level_2_split_test_y.h5\n",
            "camelyonpatch_level_2_split_train_mask.h5\n",
            "camelyonpatch_level_2_split_train_meta.csv\n",
            "camelyonpatch_level_2_split_train_x.h5\n",
            "camelyonpatch_level_2_split_train_y.h5\n",
            "camelyonpatch_level_2_split_valid_meta.csv\n",
            "camelyonpatch_level_2_split_valid_x.h5\n",
            "camelyonpatch_level_2_split_valid_y.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ_xLXgNBl4Z"
      },
      "source": [
        "# !gzip -d gdrive/MyDrive/pcamv1/camelyonpatch_level_2_split_valid_x.h5.gz\n",
        "# !gzip -d gdrive/MyDrive/pcamv1/camelyonpatch_level_2_split_test_y.h5.gz\n",
        "# !gzip -d gdrive/MyDrive/pcamv1/camelyonpatch_level_2_split_train_y.h5.gz\n",
        "# !gzip -d gdrive/MyDrive/pcamv1/camelyonpatch_level_2_split_valid_y.h5.gz\n",
        "# !gzip -d gdrive/MyDrive/pcamv1/camelyonpatch_level_2_split_test_x.h5.gz\n",
        "# !gzip -d gdrive/MyDrive/pcamv1/camelyonpatch_level_2_split_train_mask.h5.gz\n",
        "# !gzip -d gdrive/MyDrive/pcamv1/camelyonpatch_level_2_split_train_x.h5.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5NJCw3Yaz_8"
      },
      "source": [
        "# class H5_PCAM_DataModule(pl.LightningDataModule):\n",
        "  \n",
        "#   def __init__(self, path, batch_size=BATCH_SIZE):\n",
        "#     super().__init__()\n",
        "#     self.path = path\n",
        "#     self.dataset_x = None\n",
        "#     self.dataset_y = None\n",
        "\n",
        "#     self.batch_size = batch_size\n",
        "    \n",
        "#   def prepare_data(self):\n",
        "#     # train\n",
        "#     file_x_train = h5py.File(self.path + '_x.h5', 'r')\n",
        "#     file_y_train = h5py.File(self.path + '_y.h5', 'r')\n",
        "#     # validation\n",
        "#     file_x_val = h5py.File(self.path + '_x.h5', 'r')\n",
        "#     file_y_val = h5py.File(self.path + '_y.h5', 'r')\n",
        "#     # test\n",
        "#     file_x_test = h5py.File(self.path + '_x.h5', 'r')\n",
        "#     file_y_test = h5py.File(self.path + '_y.h5', 'r')\n",
        "\n",
        "#   def setup(self, stage=None):\n",
        "#     train_transforms = transforms.Compose([\n",
        "#           transforms.RandomVerticalFlip(),\n",
        "#           transforms.RandomHorizontalFlip(),\n",
        "#           transforms.ToTensor(),\n",
        "#           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "#     test_transforms = transforms.Compose([\n",
        "#           transforms.ToTensor(),\n",
        "#           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "#     ])\n",
        "\n",
        "#     self.train = (file_x_train, file_y_train)\n",
        "#     self.val = (file_x_val, file_y_val)\n",
        "#     self.test = (file_x_test, file_y_test)\n",
        "\n",
        "#   def train_dataloader(self):\n",
        "#     return DataLoader(self.train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "#   def val_dataloader(self):    \n",
        "#     return DataLoader(self.val, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "#   def test_dataloader(self):\n",
        "#     return DataLoader(self.test, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "###################\n",
        "# Transformations # This can be hyperparameters as well - like try many of it\n",
        "###################\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "class H5Dataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        self.file_path = path\n",
        "        self.dataset_x = None\n",
        "        self.dataset_y = None\n",
        "        ### Going to read the X part of the dataset - it's a different file\n",
        "        with h5py.File(self.file_path + '_x.h5', 'r') as filex:\n",
        "            self.dataset_x_len = len(filex['x'])\n",
        "\n",
        "        ### Going to read the y part of the dataset - it's a different file\n",
        "        with h5py.File(self.file_path + '_y.h5', 'r') as filey:\n",
        "            self.dataset_y_len = len(filey['y'])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.dataset_x is None:\n",
        "            self.dataset_x = h5py.File(self.file_path +'_x.h5', 'r')['x']\n",
        "        if self.dataset_y is None:\n",
        "            self.dataset_y = h5py.File(self.file_path +'_y.h5', 'r')['y']\n",
        "        return (self.dataset_x[index], self.dataset_y[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        assert self.dataset_x_len == self.dataset_y_len\n",
        "        return self.dataset_x_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VraVzn-Zoln6"
      },
      "source": [
        "# train_datamodule = H5_PCAM_DataModule(drive_base_path + 'camelyonpatch_level_2_split_train')\n",
        "# val_datamodule = H5_PCAM_DataModule(drive_base_path + 'camelyonpatch_level_2_split_valid')\n",
        "# test_datamodule = H5_PCAM_DataModule(drive_base_path + 'camelyonpatch_level_2_split_test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o0K--A4o23Y"
      },
      "source": [
        "# train_datamodule"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XBpM_0ziAuM"
      },
      "source": [
        "dataloader_params = {'batch_size': BATCH_SIZE, 'shuffle': True, 'num_workers': 2}\n",
        "\n",
        "train_path = drive_base_path + 'camelyonpatch_level_2_split_train'\n",
        "val_path = drive_base_path + 'camelyonpatch_level_2_split_valid'\n",
        "test_path = drive_base_path + 'camelyonpatch_level_2_split_test'\n",
        "\n",
        "test_dataset = H5Dataset(test_path)\n",
        "test_loader = DataLoader(test_dataset, **dataloader_params)\n",
        "\n",
        "val_dataset = H5Dataset(val_path)\n",
        "dev_loader = DataLoader(val_dataset, **dataloader_params)\n",
        "\n",
        "train_dataset = H5Dataset(train_path)\n",
        "train_loader = DataLoader(train_dataset, **dataloader_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPFBxDo7cWvC",
        "outputId": "33b05ec1-132c-4163-a882-185713d9e26c"
      },
      "source": [
        "for x, y in train_loader:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 96, 96, 3])\n",
            "torch.Size([16, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1uLntm-UsP8"
      },
      "source": [
        "### Pytorch ligthning module\n",
        "# class CNN_V2(nn.Module):\n",
        "\n",
        "class CNN_V2(pl.LightningModule):\n",
        "    \"\"\"This is the CNN That the CS230 guys have used, taken from http://cs230.stanford.edu/projects_winter_2019/posters/15813053.pdf\n",
        "       The model inheretes from nn.Module\"\"\"\n",
        "    def __init__(self, p = 0.5):\n",
        "        # log parameter\n",
        "        wandb.config.dropout = p\n",
        "        \"\"\"The init method for initializaing the CNN model\"\"\"\n",
        "        super(CNN_V2, self).__init__()\n",
        "        # 1. Convolutional layers\n",
        "        # Single image is in shape: 3x96x96 (CxHxW, H==W), RGB images\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p = p)\n",
        "        \n",
        "        # 2. FC layers to final output\n",
        "        self.fc1 = nn.Linear(in_features = 128*6*6, out_features = 512)\n",
        "        self.fc_bn1 = nn.BatchNorm1d(512)\n",
        "        self.fc2 = nn.Linear(in_features = 512, out_features = 256)\n",
        "        self.fc_bn2 = nn.BatchNorm1d(256)\n",
        "        self.fc3 = nn.Linear(in_features = 256, out_features = 128)\n",
        "        self.fc_bn3 = nn.BatchNorm1d(128)\n",
        "        self.fc4 = nn.Linear(in_features = 128, out_features = 1)\n",
        "\n",
        "        # log hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.train_acc = pl.metrics.Accuracy()\n",
        "        self.valid_acc = pl.metrics.Accuracy()\n",
        "        self.test_acc = pl.metrics.Accuracy()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply 4x...\n",
        "        # Convolution Layers, followed by Batch Normalizations, Maxpool, and ReLU\n",
        "        x = self.bn1(self.conv1(x))                      # batch_size x 96 x 96 x 16\n",
        "        x = self.pool(F.relu(x))                         # batch_size x 48 x 48 x 16\n",
        "        x = self.bn2(self.conv2(x))                      # batch_size x 48 x 48 x 32\n",
        "        x = self.pool(F.relu(x))                         # batch_size x 24 x 24 x 32\n",
        "        x = self.bn3(self.conv3(x))                      # batch_size x 24 x 24 x 64\n",
        "        x = self.pool(F.relu(x))                         # batch_size x 12 x 12 x 64\n",
        "        x = self.bn4(self.conv4(x))                      # batch_size x 12 x 12 x 128\n",
        "        x = self.pool(F.relu(x))                         # batch_size x  6 x  6 x 128\n",
        "        # Flatten the output for each image\n",
        "        x = x.reshape(-1, self.num_flat_features(x))        # batch_size x 6*6*128\n",
        "        \n",
        "        # Apply 4 FC Layers\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc_bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        x = self.fc_bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.fc3(x)\n",
        "        x = self.fc_bn3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAuksYO0U4Go"
      },
      "source": [
        "####################\n",
        "# Helper functions #\n",
        "####################\n",
        "\n",
        "def show_image(image, label):\n",
        "    \"\"\"Show image with label\"\"\"\n",
        "    print('Label: ' + str(label[0]))\n",
        "    plt.show(image)\n",
        "\n",
        "def sigmoid(x):\n",
        "    \"\"\"This method calculates the sigmoid function\"\"\"\n",
        "    return 1.0/(1.0 + np.exp(-x))\n",
        "\n",
        "def training_accuracy(predicted, true, i, acc, tpr, tnr):\n",
        "    \"\"\"Taken from https://www.kaggle.com/krishanudb/cancer-detection-deep-learning-model-using-pytorch\"\"\"\n",
        "    predicted = predicted.cpu() # Taking the predictions, why cpu and not device?\n",
        "    true = true.cpu() # Taking the labels, why cpu and not device?\n",
        "    \n",
        "    predicted = (sigmoid(predicted.data.numpy()) > 0.5) # Using sigmoid above, if prediction > 0.5 it is 1\n",
        "    true = true.data.numpy() # Numpy - can't combine above?\n",
        "    accuracy = np.sum(predicted == true) / true.shape[0] # Accuracy is: (TP + TN)/(TP + TN + FN + FP)\n",
        "    true_positive_rate = np.sum((predicted == 1) * (true == 1)) / np.sum(true == 1) # TPR: TP / (TP + FN) aka Recall\n",
        "    true_negative_rate = np.sum((predicted == 0) * (true == 0)) / np.sum(true == 0) # TNR: TN / (FP + TN)\n",
        "    acc = acc * (i) / (i + 1) + accuracy / (i + 1)\n",
        "    tpr = tpr * (i) / (i + 1) + true_positive_rate / (i + 1)\n",
        "    tnr = tnr * (i) / (i + 1) + true_negative_rate / (i + 1)\n",
        "    return acc, tpr, tnr\n",
        "\n",
        "def dev_accuracy(predicted, target):\n",
        "    \"\"\"Taken from https://www.kaggle.com/krishanudb/cancer-detection-deep-learning-model-using-pytorch\"\"\"\n",
        "    predicted = predicted.cpu()\n",
        "    target = target.cpu()\n",
        "    predicted = (sigmoid(predicted.data.numpy()) > 0.5)\n",
        "    true = target.data.numpy()\n",
        "    accuracy = np.sum(predicted == true) / true.shape[0]\n",
        "    true_positive_rate = np.sum((predicted == 1) * (true == 1)) / np.sum(true == 1)\n",
        "    true_negative_rate = np.sum((predicted == 0) * (true == 0)) / np.sum(true == 0)\n",
        "    return accuracy, true_positive_rate, true_negative_rate\n",
        "\n",
        "def train_dev_test_split_indices(dataset_size, train_split=0.8, dev_split=0.1, seed=30):\n",
        "    \"\"\"Given a dataset size, returns the train/dev/test split indices\"\"\"\n",
        "    indices = list(range(dataset_size))\n",
        "    train_split_end = int(np.floor(train_split * dataset_size))\n",
        "    dev_split_end = int(np.floor(dev_split * dataset_size)) + train_split_end\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(indices)\n",
        "    train_indices = indices[:train_split_end]\n",
        "    dev_indices = indices[train_split_end:dev_split_end]\n",
        "    test_indices = indices[dev_split_end:]\n",
        "    return train_indices, dev_indices, test_indices\n",
        "\n",
        "def train_dev_test_split_indices_from_dataset(dataset, train_split=0.8, dev_split=0.1, seed=30):\n",
        "    \"\"\"Given a dataset, returns the train/dev/test split indices\"\"\"\n",
        "    dataset_size = len(dataset)\n",
        "    indices = list(range(dataset_size))\n",
        "    train_split_end = int(np.floor(train_split * dataset_size))\n",
        "    dev_split_end = int(np.floor(dev_split * dataset_size)) + train_split_end\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(indices)\n",
        "    train_indices = indices[:train_split_end]\n",
        "    dev_indices = indices[train_split_end:dev_split_end]\n",
        "    test_indices = indices[dev_split_end:]\n",
        "    return train_indices, dev_indices, test_indices\n",
        "\n",
        "def fetch_state(epoch, model, optimizer, dev_loss_min, dev_acc_max):\n",
        "    \"\"\"Returns the state dictionary for a model and optimizer\"\"\"\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'dev_loss_min': dev_loss_min,\n",
        "        'dev_acc_max': dev_acc_max,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optim_dict': optimizer.state_dict()\n",
        "    }\n",
        "    return state\n",
        "\n",
        "def save_checkpoint(state, is_best = False, checkpoint = CHECKPOINT_DIR):\n",
        "    \"\"\"Taken from CS230 PyTorch Code Examples\"\"\"\n",
        "    \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n",
        "    checkpoint + 'best.pth.tar'\n",
        "\n",
        "    Args:\n",
        "        state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n",
        "        is_best: (bool) True if it is the best model seen till now\n",
        "        checkpoint: (string) folder where parameters are to be saved\n",
        "    \"\"\"\n",
        "    filepath = os.path.join(checkpoint, 'last_v2.pth.tar')\n",
        "    if (not os.path.exists(checkpoint)):\n",
        "        print(\"Checkpoint Directory does not exist! Making directory {}\".format(checkpoint))\n",
        "        os.mkdir(checkpoint)\n",
        "    else:\n",
        "        print(\"Checkpoint Directory exists! \")\n",
        "    torch.save(state, filepath)\n",
        "    if (is_best):\n",
        "        shutil.copyfile(filepath, os.path.join(checkpoint, 'best_v2.pth.tar'))\n",
        "        \n",
        "def load_checkpoint(model, optimizer = None, checkpoint = CHECKPOINT_DIR):\n",
        "    \"\"\"Taken from CS230 PyTorch Code Examples\"\"\"\n",
        "    \"\"\"Loads model parameters (state_dict) from file_path. If optimizer is provided, loads state_dict of\n",
        "    optimizer assuming it is present in checkpoint.\n",
        "\n",
        "    Args:\n",
        "        checkpoint: (string) filename which needs to be loaded\n",
        "        model: (torch.nn.Module) model for which the parameters are loaded\n",
        "        optimizer: (torch.optim) optional: resume optimizer from checkpoint\n",
        "    \"\"\"\n",
        "    if not os.path.exists(checkpoint):\n",
        "        print(\"File doesn't exist {}\".format(checkpoint))\n",
        "        checkpoint = None\n",
        "        return\n",
        "    checkpoint = torch.load(checkpoint)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "    if optimizer:\n",
        "        optimizer.load_state_dict(checkpoint['optim_dict'])\n",
        "\n",
        "    return checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXFh7VBVU4g5"
      },
      "source": [
        "# Parameters\n",
        "num_workers = 0\n",
        "total_epochs = 0\n",
        "num_epochs = 50\n",
        "early_stop_limit = 10\n",
        "bad_epoch_count = 0\n",
        "stop = False\n",
        "train_loss_min = np.Inf\n",
        "dev_loss_min = np.Inf\n",
        "dev_acc_max = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UH8kiJNgb7W"
      },
      "source": [
        "# Load model\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "\n",
        "model = CNN_V2()\n",
        "if (USE_GPU):\n",
        "    model.cuda()\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "lr = 5e-4\n",
        "wandb.config.learning_rate = lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbSRb6jyU7h_"
      },
      "source": [
        "# Optimizer + Loss Function\n",
        "#optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "optimizer = optim.SGD(model.parameters(), lr = lr)   # SWATS\n",
        "criterion = nn.BCEWithLogitsLoss() # Binary Cross Entropy for binary classification - malignant / benign\n",
        "\n",
        "# Load best checkpoint\n",
        "best_checkpoint = os.path.join(CHECKPOINT_DIR, 'best_v2.pth.tar');\n",
        "#checkpoint = load_checkpoint(model = model, optimizer = optimizer, checkpoint = best_checkpoint)\n",
        "# checkpoint = load_checkpoint(model = model, optimizer = None, checkpoint = best_checkpoint) # SWATS\n",
        "# total_epochs = None if checkpoint is None else checkpoint['epoch']\n",
        "total_epochs = 0\n",
        "\n",
        "# Initialize arrays for plot\n",
        "train_loss_arr = []\n",
        "train_acc_arr = []\n",
        "train_tpr_arr = []\n",
        "train_tnr_arr = []\n",
        "\n",
        "dev_loss_arr = []\n",
        "dev_acc_arr = []\n",
        "dev_tpr_arr = []\n",
        "dev_tnr_arr = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNfyyWM2VDKs",
        "outputId": "4716a48c-3007-406b-dacb-83e4ccbf6bcf"
      },
      "source": [
        "# Loop over the dataset multiple times\n",
        "total_num_epochs = total_epochs + num_epochs\n",
        "for epoch in range(num_epochs):\n",
        "    curr_epoch = total_epochs + epoch + 1\n",
        "    # Keep track of training loss\n",
        "    train_loss = []\n",
        "    # Keep track of dev loss\n",
        "    dev_loss = []\n",
        "    # Keep track of accuracy measurements\n",
        "    acc, tpr, tnr = 0.0, 0.0, 0.0\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):\n",
        "        if USE_GPU:\n",
        "            data, target = image.cuda(), label.cuda()\n",
        "        else:\n",
        "            data, target = image, label\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        # print(\"Before re-shape\", data.shape)\n",
        "        data = data.permute(0, 3, 1, 2).float() # these steps can be done in a separate class e.g. ToTensor from https://www.kaggle.com/krishanudb/cancer-detection-deep-learning-model-using-pytorch\n",
        "        # print(\"After re-shape\", data.shape)\n",
        "        output = model(data)\n",
        "        # Update target to be the same dimensions as output\n",
        "        target = target.view(output.shape[0], 1).float()\n",
        "        # Get accuracy measurements\n",
        "        acc, tpr, tnr = training_accuracy(output, target, batch_idx, acc, tpr, tnr)\n",
        "        # Calculate the batch's loss\n",
        "        curr_train_loss = criterion(output, target)\n",
        "        # Update the training loss\n",
        "        train_loss.append(curr_train_loss.item())\n",
        "        # Backward pass\n",
        "        curr_train_loss.backward()\n",
        "        # Perform a single optimization step to update parameters\n",
        "        optimizer.step()\n",
        "        # Print debug info every 64 batches\n",
        "        if (batch_idx) % 64 == 0:\n",
        "            print('Epoch {}/{}; Iter {}/{}; Loss: {:.4f}; Acc: {:.3f}; True Pos: {:.3f}; True Neg: {:.3f}'\n",
        "                   .format(curr_epoch, total_num_epochs, batch_idx + 1, len(train_loader), curr_train_loss.item(), acc, tpr, tnr))\n",
        "            \n",
        "    end_time = time.time()\n",
        "    \n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (image, label) in enumerate(dev_loader):\n",
        "            if USE_GPU:\n",
        "                data, target = image.cuda(), label.cuda()\n",
        "            else:\n",
        "                data, target = image, label\n",
        "            # Get predicted output\n",
        "            # .permute(0, 3, 1, 2)\n",
        "            # print(\"Before re-shape\", data.shape)\n",
        "            data = data.permute(0, 3, 1, 2).float()\n",
        "            # print(\"After re-shape\", data.shape)\n",
        "            output = model(data)\n",
        "            # Update target to be the same dimensions as output\n",
        "            target = target.view(output.shape[0], 1).float()\n",
        "            # Get accuracy measurements\n",
        "            dev_acc, dev_tpr, dev_tnr = dev_accuracy(output, target)\n",
        "            # Calculate the batch's loss\n",
        "            curr_dev_loss = criterion(output, target)\n",
        "            # Update the dev loss\n",
        "            dev_loss.append(curr_dev_loss.item())\n",
        "    \n",
        "    # Calculate average loss\n",
        "    avg_train_loss = np.mean(np.array(train_loss))\n",
        "    avg_dev_loss = np.mean(np.array(dev_loss))\n",
        "    \n",
        "    # Update dev loss arrays\n",
        "    dev_loss_arr.append(avg_dev_loss)\n",
        "    dev_acc_arr.append(dev_acc)\n",
        "    dev_tpr_arr.append(dev_tpr)\n",
        "    dev_tnr_arr.append(dev_tnr)\n",
        "\n",
        "    # Update training loss arrays\n",
        "    train_loss_arr.append(avg_train_loss)\n",
        "    train_acc_arr.append(acc)\n",
        "    train_tpr_arr.append(tpr)\n",
        "    train_tnr_arr.append(tnr)\n",
        "\n",
        "    print('Epoch {}/{}; Avg. Train Loss: {:.4f}; Train Acc: {:.3f}; Train TPR: {:.3f}; Train TNR: {:.3f}; Epoch Time: {} mins; \\nAvg. Dev Loss: {:.4f}; Dev Acc: {:.3f}; Dev TPR: {:.3f}; Dev TNR: {:.3f}\\n'\n",
        "        .format(curr_epoch, total_num_epochs, avg_train_loss, acc, tpr, tnr, round((end_time - start_time)/ 60., 2), avg_dev_loss, dev_acc, dev_tpr, dev_tnr))\n",
        "    \n",
        "    wandb.log({'epoch': curr_epoch, 'loss': avg_train_loss, 'accuracy': acc, 'tpr': tpr, 'time_per_epoch_min': round((end_time - start_time)/ 60., 2)})\n",
        "\n",
        "    if avg_dev_loss < dev_loss_min:\n",
        "        print('Dev loss decreased ({:.6f} --> {:.6f}).  Saving model ...'\n",
        "              .format(dev_loss_min, avg_dev_loss))\n",
        "        dev_loss_min = avg_dev_loss\n",
        "        is_best = False\n",
        "        if (dev_acc >= dev_acc_max):\n",
        "            is_best = True\n",
        "            dev_acc_max = dev_acc\n",
        "        state = fetch_state(epoch = curr_epoch, model = model, optimizer = optimizer, \n",
        "                            dev_loss_min = dev_loss_min, \n",
        "                            dev_acc_max = dev_acc_max)\n",
        "        save_checkpoint(state = state, is_best = is_best)\n",
        "        bad_epoch_count = 0\n",
        "    # If dev loss didn't improve, increase bad_epoch_count and stop if\n",
        "    # bad_epoch_count >= early_stop_limit\n",
        "    else:\n",
        "        bad_epoch_count += 1\n",
        "        print('{} epochs of increasing dev loss ({:.6f} --> {:.6f}).'\n",
        "              .format(bad_epoch_count, dev_loss_min, avg_dev_loss))\n",
        "        if (bad_epoch_count >= early_stop_limit):\n",
        "            print('Stopping training')\n",
        "            stop = True\n",
        "\n",
        "    if (stop):\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50; Iter 1/16384; Loss: 0.7694; Acc: 0.500; True Pos: 0.333; True Neg: 0.714\n",
            "Epoch 1/50; Iter 65/16384; Loss: 0.7352; Acc: 0.514; True Pos: 0.316; True Neg: 0.724\n",
            "Epoch 1/50; Iter 129/16384; Loss: 0.6738; Acc: 0.534; True Pos: 0.342; True Neg: 0.738\n",
            "Epoch 1/50; Iter 193/16384; Loss: 0.7965; Acc: 0.548; True Pos: 0.372; True Neg: 0.734\n",
            "Epoch 1/50; Iter 257/16384; Loss: 0.5914; Acc: 0.561; True Pos: 0.398; True Neg: 0.733\n",
            "Epoch 1/50; Iter 321/16384; Loss: 0.7078; Acc: 0.572; True Pos: 0.418; True Neg: 0.737\n",
            "Epoch 1/50; Iter 385/16384; Loss: 0.6352; Acc: 0.582; True Pos: 0.443; True Neg: 0.735\n",
            "Epoch 1/50; Iter 449/16384; Loss: 0.5575; Acc: 0.588; True Pos: 0.458; True Neg: 0.733\n",
            "Epoch 1/50; Iter 513/16384; Loss: 0.6130; Acc: 0.593; True Pos: 0.473; True Neg: 0.728\n",
            "Epoch 1/50; Iter 577/16384; Loss: 0.5980; Acc: 0.597; True Pos: 0.487; True Neg: 0.723\n",
            "Epoch 1/50; Iter 641/16384; Loss: 0.6307; Acc: 0.603; True Pos: 0.498; True Neg: 0.723\n",
            "Epoch 1/50; Iter 705/16384; Loss: 0.5781; Acc: 0.606; True Pos: 0.509; True Neg: 0.720\n",
            "Epoch 1/50; Iter 769/16384; Loss: 0.5414; Acc: 0.610; True Pos: 0.520; True Neg: 0.719\n",
            "Epoch 1/50; Iter 833/16384; Loss: 0.6046; Acc: 0.616; True Pos: 0.533; True Neg: 0.717\n",
            "Epoch 1/50; Iter 897/16384; Loss: 0.7280; Acc: 0.620; True Pos: 0.543; True Neg: 0.715\n",
            "Epoch 1/50; Iter 961/16384; Loss: 0.4799; Acc: 0.625; True Pos: 0.552; True Neg: 0.716\n",
            "Epoch 1/50; Iter 1025/16384; Loss: 0.5865; Acc: 0.631; True Pos: 0.563; True Neg: 0.717\n",
            "Epoch 1/50; Iter 1089/16384; Loss: 0.4428; Acc: 0.635; True Pos: 0.571; True Neg: 0.717\n",
            "Epoch 1/50; Iter 1153/16384; Loss: 0.4836; Acc: 0.638; True Pos: 0.577; True Neg: 0.718\n",
            "Epoch 1/50; Iter 1217/16384; Loss: 0.5960; Acc: 0.642; True Pos: 0.585; True Neg: 0.718\n",
            "Epoch 1/50; Iter 1281/16384; Loss: 0.4447; Acc: 0.647; True Pos: 0.594; True Neg: 0.719\n",
            "Epoch 1/50; Iter 1345/16384; Loss: 0.7259; Acc: 0.650; True Pos: 0.599; True Neg: 0.719\n",
            "Epoch 1/50; Iter 1409/16384; Loss: 0.4467; Acc: 0.653; True Pos: 0.605; True Neg: 0.720\n",
            "Epoch 1/50; Iter 1473/16384; Loss: 0.5567; Acc: 0.656; True Pos: 0.611; True Neg: 0.721\n",
            "Epoch 1/50; Iter 1537/16384; Loss: 0.5127; Acc: 0.657; True Pos: 0.615; True Neg: 0.720\n",
            "Epoch 1/50; Iter 1601/16384; Loss: 0.7459; Acc: 0.659; True Pos: 0.620; True Neg: 0.719\n",
            "Epoch 1/50; Iter 1665/16384; Loss: 0.5692; Acc: 0.661; True Pos: 0.624; True Neg: 0.719\n",
            "Epoch 1/50; Iter 1729/16384; Loss: 0.4294; Acc: 0.663; True Pos: 0.629; True Neg: 0.719\n",
            "Epoch 1/50; Iter 1793/16384; Loss: 0.4584; Acc: 0.666; True Pos: 0.633; True Neg: 0.720\n",
            "Epoch 1/50; Iter 1857/16384; Loss: 0.5509; Acc: 0.668; True Pos: 0.636; True Neg: 0.720\n",
            "Epoch 1/50; Iter 1921/16384; Loss: 0.7175; Acc: 0.670; True Pos: 0.640; True Neg: 0.721\n",
            "Epoch 1/50; Iter 1985/16384; Loss: 0.5979; Acc: 0.672; True Pos: 0.643; True Neg: 0.721\n",
            "Epoch 1/50; Iter 2049/16384; Loss: 0.6535; Acc: 0.674; True Pos: 0.646; True Neg: 0.722\n",
            "Epoch 1/50; Iter 2113/16384; Loss: 0.4845; Acc: 0.676; True Pos: 0.649; True Neg: 0.724\n",
            "Epoch 1/50; Iter 2177/16384; Loss: 0.4702; Acc: 0.678; True Pos: 0.652; True Neg: 0.725\n",
            "Epoch 1/50; Iter 2241/16384; Loss: 0.6727; Acc: 0.680; True Pos: 0.655; True Neg: 0.726\n",
            "Epoch 1/50; Iter 2305/16384; Loss: 0.5205; Acc: 0.682; True Pos: 0.658; True Neg: 0.727\n",
            "Epoch 1/50; Iter 2369/16384; Loss: 0.4607; Acc: 0.684; True Pos: 0.662; True Neg: 0.728\n",
            "Epoch 1/50; Iter 2433/16384; Loss: 0.6299; Acc: 0.685; True Pos: 0.663; True Neg: 0.730\n",
            "Epoch 1/50; Iter 2497/16384; Loss: 0.6938; Acc: 0.687; True Pos: 0.666; True Neg: 0.730\n",
            "Epoch 1/50; Iter 2561/16384; Loss: 0.4674; Acc: 0.689; True Pos: 0.668; True Neg: 0.732\n",
            "Epoch 1/50; Iter 2625/16384; Loss: 0.4734; Acc: 0.690; True Pos: 0.670; True Neg: 0.733\n",
            "Epoch 1/50; Iter 2689/16384; Loss: 0.4674; Acc: 0.691; True Pos: 0.672; True Neg: 0.733\n",
            "Epoch 1/50; Iter 2753/16384; Loss: 0.4992; Acc: 0.693; True Pos: 0.675; True Neg: 0.733\n",
            "Epoch 1/50; Iter 2817/16384; Loss: 0.3471; Acc: 0.694; True Pos: 0.677; True Neg: 0.734\n",
            "Epoch 1/50; Iter 2881/16384; Loss: 0.6463; Acc: 0.696; True Pos: 0.679; True Neg: 0.735\n",
            "Epoch 1/50; Iter 2945/16384; Loss: 0.4712; Acc: 0.697; True Pos: 0.681; True Neg: 0.736\n",
            "Epoch 1/50; Iter 3009/16384; Loss: 0.7641; Acc: 0.698; True Pos: 0.683; True Neg: 0.736\n",
            "Epoch 1/50; Iter 3073/16384; Loss: 0.6885; Acc: 0.699; True Pos: 0.685; True Neg: 0.737\n",
            "Epoch 1/50; Iter 3137/16384; Loss: 0.6743; Acc: 0.700; True Pos: 0.686; True Neg: 0.737\n",
            "Epoch 1/50; Iter 3201/16384; Loss: 0.5255; Acc: 0.701; True Pos: 0.687; True Neg: 0.738\n",
            "Epoch 1/50; Iter 3265/16384; Loss: 0.6902; Acc: 0.702; True Pos: 0.689; True Neg: 0.738\n",
            "Epoch 1/50; Iter 3329/16384; Loss: 0.4897; Acc: 0.703; True Pos: 0.690; True Neg: 0.739\n",
            "Epoch 1/50; Iter 3393/16384; Loss: 0.6805; Acc: 0.704; True Pos: 0.691; True Neg: 0.739\n",
            "Epoch 1/50; Iter 3457/16384; Loss: 0.5518; Acc: 0.705; True Pos: 0.693; True Neg: 0.740\n",
            "Epoch 1/50; Iter 3521/16384; Loss: 0.6683; Acc: 0.706; True Pos: 0.694; True Neg: 0.740\n",
            "Epoch 1/50; Iter 3585/16384; Loss: 0.8187; Acc: 0.706; True Pos: 0.695; True Neg: 0.741\n",
            "Epoch 1/50; Iter 3649/16384; Loss: 0.3610; Acc: 0.707; True Pos: 0.697; True Neg: 0.741\n",
            "Epoch 1/50; Iter 3713/16384; Loss: 0.4591; Acc: 0.708; True Pos: 0.698; True Neg: 0.742\n",
            "Epoch 1/50; Iter 3777/16384; Loss: 0.4628; Acc: 0.709; True Pos: 0.699; True Neg: 0.743\n",
            "Epoch 1/50; Iter 3841/16384; Loss: 0.3876; Acc: 0.710; True Pos: 0.700; True Neg: 0.743\n",
            "Epoch 1/50; Iter 3905/16384; Loss: 0.6410; Acc: 0.711; True Pos: 0.701; True Neg: 0.744\n",
            "Epoch 1/50; Iter 3969/16384; Loss: 0.6111; Acc: 0.712; True Pos: 0.703; True Neg: 0.744\n",
            "Epoch 1/50; Iter 4033/16384; Loss: 0.5465; Acc: 0.713; True Pos: 0.704; True Neg: 0.745\n",
            "Epoch 1/50; Iter 4097/16384; Loss: 0.4360; Acc: 0.714; True Pos: 0.706; True Neg: 0.745\n",
            "Epoch 1/50; Iter 4161/16384; Loss: 0.4239; Acc: 0.714; True Pos: 0.707; True Neg: 0.745\n",
            "Epoch 1/50; Iter 4225/16384; Loss: 0.5554; Acc: 0.715; True Pos: 0.708; True Neg: 0.745\n",
            "Epoch 1/50; Iter 4289/16384; Loss: 0.4475; Acc: 0.716; True Pos: 0.710; True Neg: 0.746\n",
            "Epoch 1/50; Iter 4353/16384; Loss: 0.5924; Acc: 0.716; True Pos: 0.711; True Neg: 0.746\n",
            "Epoch 1/50; Iter 4417/16384; Loss: 0.5389; Acc: 0.717; True Pos: 0.712; True Neg: 0.747\n",
            "Epoch 1/50; Iter 4481/16384; Loss: 0.4663; Acc: 0.718; True Pos: 0.713; True Neg: 0.747\n",
            "Epoch 1/50; Iter 4545/16384; Loss: 0.5300; Acc: 0.718; True Pos: 0.714; True Neg: 0.747\n",
            "Epoch 1/50; Iter 4609/16384; Loss: 0.5523; Acc: 0.719; True Pos: 0.715; True Neg: 0.748\n",
            "Epoch 1/50; Iter 4673/16384; Loss: 0.2941; Acc: 0.720; True Pos: 0.716; True Neg: 0.748\n",
            "Epoch 1/50; Iter 4737/16384; Loss: 0.3565; Acc: 0.720; True Pos: 0.717; True Neg: 0.748\n",
            "Epoch 1/50; Iter 4801/16384; Loss: 0.3767; Acc: 0.721; True Pos: 0.718; True Neg: 0.748\n",
            "Epoch 1/50; Iter 4865/16384; Loss: 0.5545; Acc: 0.721; True Pos: 0.719; True Neg: 0.749\n",
            "Epoch 1/50; Iter 4929/16384; Loss: 0.2082; Acc: 0.722; True Pos: 0.719; True Neg: 0.749\n",
            "Epoch 1/50; Iter 4993/16384; Loss: 0.5707; Acc: 0.722; True Pos: 0.720; True Neg: 0.749\n",
            "Epoch 1/50; Iter 5057/16384; Loss: 0.4878; Acc: 0.723; True Pos: 0.721; True Neg: 0.750\n",
            "Epoch 1/50; Iter 5121/16384; Loss: 0.6466; Acc: 0.724; True Pos: 0.722; True Neg: 0.751\n",
            "Epoch 1/50; Iter 5185/16384; Loss: 0.6347; Acc: 0.724; True Pos: 0.722; True Neg: 0.751\n",
            "Epoch 1/50; Iter 5249/16384; Loss: 0.5897; Acc: 0.725; True Pos: 0.723; True Neg: 0.751\n",
            "Epoch 1/50; Iter 5313/16384; Loss: 0.4203; Acc: 0.726; True Pos: 0.724; True Neg: 0.752\n",
            "Epoch 1/50; Iter 5377/16384; Loss: 0.3980; Acc: 0.726; True Pos: 0.725; True Neg: 0.752\n",
            "Epoch 1/50; Iter 5441/16384; Loss: 0.8710; Acc: 0.727; True Pos: 0.726; True Neg: 0.753\n",
            "Epoch 1/50; Iter 5505/16384; Loss: 0.6451; Acc: 0.727; True Pos: 0.727; True Neg: 0.753\n",
            "Epoch 1/50; Iter 5569/16384; Loss: 0.4119; Acc: 0.728; True Pos: 0.727; True Neg: 0.754\n",
            "Epoch 1/50; Iter 5633/16384; Loss: 0.3570; Acc: 0.729; True Pos: 0.728; True Neg: 0.754\n",
            "Epoch 1/50; Iter 5697/16384; Loss: 0.3249; Acc: 0.729; True Pos: 0.729; True Neg: 0.754\n",
            "Epoch 1/50; Iter 5761/16384; Loss: 0.6778; Acc: 0.729; True Pos: 0.730; True Neg: 0.755\n",
            "Epoch 1/50; Iter 5825/16384; Loss: 0.6513; Acc: 0.730; True Pos: 0.730; True Neg: 0.755\n",
            "Epoch 1/50; Iter 5889/16384; Loss: 0.3770; Acc: 0.731; True Pos: 0.731; True Neg: 0.756\n",
            "Epoch 1/50; Iter 5953/16384; Loss: 0.6632; Acc: 0.731; True Pos: 0.732; True Neg: 0.756\n",
            "Epoch 1/50; Iter 6017/16384; Loss: 0.6313; Acc: 0.732; True Pos: 0.732; True Neg: 0.757\n",
            "Epoch 1/50; Iter 6081/16384; Loss: 0.5608; Acc: 0.732; True Pos: 0.733; True Neg: 0.757\n",
            "Epoch 1/50; Iter 6145/16384; Loss: 0.4418; Acc: 0.733; True Pos: 0.733; True Neg: 0.757\n",
            "Epoch 1/50; Iter 6209/16384; Loss: 0.3026; Acc: 0.733; True Pos: 0.734; True Neg: 0.758\n",
            "Epoch 1/50; Iter 6273/16384; Loss: 0.3905; Acc: 0.734; True Pos: 0.735; True Neg: 0.758\n",
            "Epoch 1/50; Iter 6337/16384; Loss: 0.2487; Acc: 0.734; True Pos: 0.735; True Neg: 0.759\n",
            "Epoch 1/50; Iter 6401/16384; Loss: 0.5155; Acc: 0.735; True Pos: 0.736; True Neg: 0.759\n",
            "Epoch 1/50; Iter 6465/16384; Loss: 0.6069; Acc: 0.735; True Pos: 0.736; True Neg: 0.759\n",
            "Epoch 1/50; Iter 6529/16384; Loss: 0.4663; Acc: 0.735; True Pos: 0.737; True Neg: 0.760\n",
            "Epoch 1/50; Iter 6593/16384; Loss: 0.4861; Acc: 0.736; True Pos: 0.738; True Neg: 0.760\n",
            "Epoch 1/50; Iter 6657/16384; Loss: 0.5013; Acc: 0.736; True Pos: 0.738; True Neg: 0.760\n",
            "Epoch 1/50; Iter 6721/16384; Loss: 0.5300; Acc: 0.737; True Pos: 0.739; True Neg: 0.760\n",
            "Epoch 1/50; Iter 6785/16384; Loss: 0.5923; Acc: 0.737; True Pos: 0.739; True Neg: 0.760\n",
            "Epoch 1/50; Iter 6849/16384; Loss: 0.4000; Acc: 0.738; True Pos: 0.740; True Neg: 0.761\n",
            "Epoch 1/50; Iter 6913/16384; Loss: 0.2884; Acc: 0.738; True Pos: 0.740; True Neg: 0.761\n",
            "Epoch 1/50; Iter 6977/16384; Loss: 0.4109; Acc: 0.738; True Pos: 0.741; True Neg: 0.761\n",
            "Epoch 1/50; Iter 7041/16384; Loss: 0.3846; Acc: 0.739; True Pos: 0.742; True Neg: 0.762\n",
            "Epoch 1/50; Iter 7105/16384; Loss: 0.3617; Acc: 0.740; True Pos: 0.742; True Neg: 0.762\n",
            "Epoch 1/50; Iter 7169/16384; Loss: 0.4120; Acc: 0.740; True Pos: 0.743; True Neg: 0.763\n",
            "Epoch 1/50; Iter 7233/16384; Loss: 0.4658; Acc: 0.740; True Pos: 0.744; True Neg: 0.763\n",
            "Epoch 1/50; Iter 7297/16384; Loss: 0.4344; Acc: 0.741; True Pos: 0.744; True Neg: 0.763\n",
            "Epoch 1/50; Iter 7361/16384; Loss: 0.5347; Acc: 0.741; True Pos: 0.745; True Neg: 0.764\n",
            "Epoch 1/50; Iter 7425/16384; Loss: 0.5197; Acc: 0.742; True Pos: 0.745; True Neg: 0.764\n",
            "Epoch 1/50; Iter 7489/16384; Loss: 0.6331; Acc: 0.742; True Pos: 0.746; True Neg: 0.764\n",
            "Epoch 1/50; Iter 7553/16384; Loss: 0.4041; Acc: 0.742; True Pos: 0.746; True Neg: 0.765\n",
            "Epoch 1/50; Iter 7617/16384; Loss: 0.4864; Acc: 0.743; True Pos: 0.747; True Neg: 0.765\n",
            "Epoch 1/50; Iter 7681/16384; Loss: 0.4532; Acc: 0.743; True Pos: 0.747; True Neg: 0.765\n",
            "Epoch 1/50; Iter 7745/16384; Loss: 0.6030; Acc: 0.743; True Pos: 0.748; True Neg: 0.765\n",
            "Epoch 1/50; Iter 7809/16384; Loss: 0.4647; Acc: 0.744; True Pos: 0.748; True Neg: 0.766\n",
            "Epoch 1/50; Iter 7873/16384; Loss: 0.3065; Acc: 0.744; True Pos: 0.749; True Neg: 0.767\n",
            "Epoch 1/50; Iter 7937/16384; Loss: 0.4450; Acc: 0.745; True Pos: 0.749; True Neg: 0.767\n",
            "Epoch 1/50; Iter 8001/16384; Loss: 0.3490; Acc: 0.745; True Pos: 0.750; True Neg: 0.767\n",
            "Epoch 1/50; Iter 8065/16384; Loss: 0.2620; Acc: 0.746; True Pos: 0.750; True Neg: 0.768\n",
            "Epoch 1/50; Iter 8129/16384; Loss: 0.3301; Acc: 0.746; True Pos: 0.751; True Neg: 0.768\n",
            "Epoch 1/50; Iter 8193/16384; Loss: 0.4135; Acc: 0.746; True Pos: 0.751; True Neg: 0.768\n",
            "Epoch 1/50; Iter 8257/16384; Loss: 0.5782; Acc: 0.747; True Pos: 0.751; True Neg: 0.769\n",
            "Epoch 1/50; Iter 8321/16384; Loss: 0.5978; Acc: 0.747; True Pos: 0.752; True Neg: 0.769\n",
            "Epoch 1/50; Iter 8385/16384; Loss: 0.5677; Acc: 0.748; True Pos: 0.752; True Neg: 0.769\n",
            "Epoch 1/50; Iter 8449/16384; Loss: 0.6056; Acc: 0.748; True Pos: 0.753; True Neg: 0.769\n",
            "Epoch 1/50; Iter 8513/16384; Loss: 0.5830; Acc: 0.748; True Pos: 0.754; True Neg: 0.769\n",
            "Epoch 1/50; Iter 8577/16384; Loss: 0.5020; Acc: 0.749; True Pos: 0.754; True Neg: 0.770\n",
            "Epoch 1/50; Iter 8641/16384; Loss: 0.5925; Acc: 0.749; True Pos: 0.755; True Neg: 0.770\n",
            "Epoch 1/50; Iter 8705/16384; Loss: 0.3900; Acc: 0.749; True Pos: 0.755; True Neg: 0.770\n",
            "Epoch 1/50; Iter 8769/16384; Loss: 0.2809; Acc: 0.750; True Pos: 0.755; True Neg: 0.771\n",
            "Epoch 1/50; Iter 8833/16384; Loss: 0.4348; Acc: 0.750; True Pos: 0.756; True Neg: 0.771\n",
            "Epoch 1/50; Iter 8897/16384; Loss: 0.3715; Acc: 0.750; True Pos: 0.756; True Neg: 0.772\n",
            "Epoch 1/50; Iter 8961/16384; Loss: 0.4044; Acc: 0.751; True Pos: 0.756; True Neg: 0.772\n",
            "Epoch 1/50; Iter 9025/16384; Loss: 0.3616; Acc: 0.751; True Pos: 0.757; True Neg: 0.772\n",
            "Epoch 1/50; Iter 9089/16384; Loss: 0.4755; Acc: 0.751; True Pos: 0.757; True Neg: 0.772\n",
            "Epoch 1/50; Iter 9153/16384; Loss: 0.6940; Acc: 0.752; True Pos: 0.758; True Neg: 0.773\n",
            "Epoch 1/50; Iter 9217/16384; Loss: 0.9455; Acc: 0.752; True Pos: 0.758; True Neg: 0.773\n",
            "Epoch 1/50; Iter 9281/16384; Loss: 0.5373; Acc: 0.752; True Pos: 0.759; True Neg: 0.773\n",
            "Epoch 1/50; Iter 9345/16384; Loss: 0.3412; Acc: 0.753; True Pos: 0.759; True Neg: 0.773\n",
            "Epoch 1/50; Iter 9409/16384; Loss: 0.3332; Acc: 0.753; True Pos: 0.759; True Neg: 0.774\n",
            "Epoch 1/50; Iter 9473/16384; Loss: 0.4491; Acc: 0.753; True Pos: 0.760; True Neg: 0.774\n",
            "Epoch 1/50; Iter 9537/16384; Loss: 0.2828; Acc: 0.754; True Pos: 0.760; True Neg: 0.775\n",
            "Epoch 1/50; Iter 9601/16384; Loss: 0.2195; Acc: 0.754; True Pos: 0.760; True Neg: 0.775\n",
            "Epoch 1/50; Iter 9665/16384; Loss: 0.3181; Acc: 0.755; True Pos: 0.761; True Neg: 0.775\n",
            "Epoch 1/50; Iter 9729/16384; Loss: 0.5826; Acc: 0.755; True Pos: 0.761; True Neg: 0.776\n",
            "Epoch 1/50; Iter 9793/16384; Loss: 0.4277; Acc: 0.755; True Pos: 0.761; True Neg: 0.776\n",
            "Epoch 1/50; Iter 9857/16384; Loss: 0.3251; Acc: 0.756; True Pos: 0.762; True Neg: 0.776\n",
            "Epoch 1/50; Iter 9921/16384; Loss: 0.3105; Acc: 0.756; True Pos: 0.762; True Neg: 0.776\n",
            "Epoch 1/50; Iter 9985/16384; Loss: 0.5680; Acc: 0.756; True Pos: 0.763; True Neg: 0.777\n",
            "Epoch 1/50; Iter 10049/16384; Loss: 0.3962; Acc: 0.757; True Pos: 0.763; True Neg: 0.777\n",
            "Epoch 1/50; Iter 10113/16384; Loss: 0.3893; Acc: 0.757; True Pos: 0.764; True Neg: 0.777\n",
            "Epoch 1/50; Iter 10177/16384; Loss: 0.5314; Acc: 0.757; True Pos: 0.764; True Neg: 0.777\n",
            "Epoch 1/50; Iter 10241/16384; Loss: 0.5760; Acc: 0.757; True Pos: 0.764; True Neg: 0.778\n",
            "Epoch 1/50; Iter 10305/16384; Loss: 0.4605; Acc: 0.758; True Pos: 0.765; True Neg: 0.778\n",
            "Epoch 1/50; Iter 10369/16384; Loss: 0.5773; Acc: 0.758; True Pos: 0.765; True Neg: 0.779\n",
            "Epoch 1/50; Iter 10433/16384; Loss: 0.3605; Acc: 0.758; True Pos: 0.765; True Neg: 0.779\n",
            "Epoch 1/50; Iter 10497/16384; Loss: 0.3512; Acc: 0.758; True Pos: 0.765; True Neg: 0.779\n",
            "Epoch 1/50; Iter 10561/16384; Loss: 0.3033; Acc: 0.759; True Pos: 0.766; True Neg: 0.779\n",
            "Epoch 1/50; Iter 10625/16384; Loss: 0.4830; Acc: 0.759; True Pos: 0.766; True Neg: 0.779\n",
            "Epoch 1/50; Iter 10689/16384; Loss: 0.5651; Acc: 0.759; True Pos: 0.766; True Neg: 0.779\n",
            "Epoch 1/50; Iter 10753/16384; Loss: 0.4070; Acc: 0.759; True Pos: 0.766; True Neg: 0.780\n",
            "Epoch 1/50; Iter 10817/16384; Loss: 0.3297; Acc: 0.759; True Pos: 0.766; True Neg: 0.780\n",
            "Epoch 1/50; Iter 10881/16384; Loss: 0.4244; Acc: 0.760; True Pos: 0.767; True Neg: 0.780\n",
            "Epoch 1/50; Iter 10945/16384; Loss: 0.4030; Acc: 0.760; True Pos: 0.767; True Neg: 0.780\n",
            "Epoch 1/50; Iter 11009/16384; Loss: 0.5119; Acc: 0.760; True Pos: 0.767; True Neg: 0.780\n",
            "Epoch 1/50; Iter 11073/16384; Loss: 0.4027; Acc: 0.760; True Pos: 0.767; True Neg: 0.780\n",
            "Epoch 1/50; Iter 11137/16384; Loss: 0.5990; Acc: 0.761; True Pos: 0.768; True Neg: 0.781\n",
            "Epoch 1/50; Iter 11201/16384; Loss: 0.4281; Acc: 0.761; True Pos: 0.768; True Neg: 0.781\n",
            "Epoch 1/50; Iter 11265/16384; Loss: 0.2687; Acc: 0.761; True Pos: 0.768; True Neg: 0.781\n",
            "Epoch 1/50; Iter 11329/16384; Loss: 0.3438; Acc: 0.761; True Pos: 0.769; True Neg: 0.781\n",
            "Epoch 1/50; Iter 11393/16384; Loss: 0.5599; Acc: 0.761; True Pos: 0.769; True Neg: 0.781\n",
            "Epoch 1/50; Iter 11457/16384; Loss: 0.3393; Acc: 0.762; True Pos: 0.769; True Neg: 0.782\n",
            "Epoch 1/50; Iter 11521/16384; Loss: 0.2895; Acc: 0.762; True Pos: 0.769; True Neg: 0.782\n",
            "Epoch 1/50; Iter 11585/16384; Loss: 0.4866; Acc: 0.762; True Pos: 0.770; True Neg: 0.782\n",
            "Epoch 1/50; Iter 11649/16384; Loss: 0.2576; Acc: 0.763; True Pos: 0.770; True Neg: 0.782\n",
            "Epoch 1/50; Iter 11713/16384; Loss: 0.1999; Acc: 0.763; True Pos: 0.770; True Neg: 0.783\n",
            "Epoch 1/50; Iter 11777/16384; Loss: 0.3252; Acc: 0.763; True Pos: 0.771; True Neg: 0.783\n",
            "Epoch 1/50; Iter 11841/16384; Loss: 0.3725; Acc: 0.763; True Pos: 0.771; True Neg: 0.783\n",
            "Epoch 1/50; Iter 11905/16384; Loss: 0.3639; Acc: 0.764; True Pos: 0.771; True Neg: 0.783\n",
            "Epoch 1/50; Iter 11969/16384; Loss: 0.3056; Acc: 0.764; True Pos: 0.772; True Neg: 0.784\n",
            "Epoch 1/50; Iter 12033/16384; Loss: 0.5300; Acc: 0.764; True Pos: 0.772; True Neg: 0.784\n",
            "Epoch 1/50; Iter 12097/16384; Loss: 0.4552; Acc: 0.764; True Pos: 0.772; True Neg: 0.784\n",
            "Epoch 1/50; Iter 12161/16384; Loss: 0.3117; Acc: 0.764; True Pos: 0.772; True Neg: 0.784\n",
            "Epoch 1/50; Iter 12225/16384; Loss: 0.8804; Acc: 0.764; True Pos: 0.772; True Neg: 0.784\n",
            "Epoch 1/50; Iter 12289/16384; Loss: 0.4820; Acc: 0.765; True Pos: 0.773; True Neg: 0.784\n",
            "Epoch 1/50; Iter 12353/16384; Loss: 0.4610; Acc: 0.765; True Pos: 0.773; True Neg: 0.785\n",
            "Epoch 1/50; Iter 12417/16384; Loss: 0.5847; Acc: 0.765; True Pos: 0.773; True Neg: 0.785\n",
            "Epoch 1/50; Iter 12481/16384; Loss: 0.4702; Acc: 0.765; True Pos: 0.773; True Neg: 0.785\n",
            "Epoch 1/50; Iter 12545/16384; Loss: 0.5867; Acc: 0.765; True Pos: 0.773; True Neg: 0.785\n",
            "Epoch 1/50; Iter 12609/16384; Loss: 0.3001; Acc: 0.766; True Pos: 0.774; True Neg: 0.786\n",
            "Epoch 1/50; Iter 12673/16384; Loss: 0.4516; Acc: 0.766; True Pos: 0.774; True Neg: 0.786\n",
            "Epoch 1/50; Iter 12737/16384; Loss: 0.5577; Acc: 0.766; True Pos: 0.774; True Neg: 0.786\n",
            "Epoch 1/50; Iter 12801/16384; Loss: 0.7384; Acc: 0.766; True Pos: 0.775; True Neg: 0.786\n",
            "Epoch 1/50; Iter 12865/16384; Loss: 0.7123; Acc: 0.767; True Pos: 0.775; True Neg: 0.786\n",
            "Epoch 1/50; Iter 12929/16384; Loss: 0.4274; Acc: 0.767; True Pos: 0.775; True Neg: 0.787\n",
            "Epoch 1/50; Iter 12993/16384; Loss: 0.4663; Acc: 0.767; True Pos: 0.775; True Neg: 0.787\n",
            "Epoch 1/50; Iter 13057/16384; Loss: 0.3180; Acc: 0.767; True Pos: 0.776; True Neg: 0.787\n",
            "Epoch 1/50; Iter 13121/16384; Loss: 0.3862; Acc: 0.768; True Pos: 0.776; True Neg: 0.787\n",
            "Epoch 1/50; Iter 13185/16384; Loss: 0.4464; Acc: 0.768; True Pos: 0.776; True Neg: 0.788\n",
            "Epoch 1/50; Iter 13249/16384; Loss: 0.4080; Acc: 0.768; True Pos: 0.776; True Neg: 0.788\n",
            "Epoch 1/50; Iter 13313/16384; Loss: 0.2975; Acc: 0.768; True Pos: 0.777; True Neg: 0.788\n",
            "Epoch 1/50; Iter 13377/16384; Loss: 0.2919; Acc: 0.769; True Pos: 0.777; True Neg: 0.788\n",
            "Epoch 1/50; Iter 13441/16384; Loss: 0.1853; Acc: 0.769; True Pos: 0.777; True Neg: 0.788\n",
            "Epoch 1/50; Iter 13505/16384; Loss: 0.2820; Acc: 0.769; True Pos: 0.777; True Neg: 0.789\n",
            "Epoch 1/50; Iter 13569/16384; Loss: 0.5616; Acc: 0.769; True Pos: 0.777; True Neg: 0.789\n",
            "Epoch 1/50; Iter 13633/16384; Loss: 0.4650; Acc: 0.769; True Pos: 0.778; True Neg: 0.789\n",
            "Epoch 1/50; Iter 13697/16384; Loss: 0.2968; Acc: 0.769; True Pos: 0.778; True Neg: 0.789\n",
            "Epoch 1/50; Iter 13761/16384; Loss: 0.5491; Acc: 0.770; True Pos: 0.778; True Neg: 0.789\n",
            "Epoch 1/50; Iter 13825/16384; Loss: 0.3393; Acc: 0.770; True Pos: 0.778; True Neg: 0.789\n",
            "Epoch 1/50; Iter 13889/16384; Loss: 0.3058; Acc: 0.770; True Pos: 0.778; True Neg: 0.789\n",
            "Epoch 1/50; Iter 13953/16384; Loss: 0.4783; Acc: 0.770; True Pos: 0.779; True Neg: 0.790\n",
            "Epoch 1/50; Iter 14017/16384; Loss: 0.4735; Acc: 0.770; True Pos: 0.779; True Neg: 0.790\n",
            "Epoch 1/50; Iter 14081/16384; Loss: 0.5270; Acc: 0.771; True Pos: 0.779; True Neg: 0.790\n",
            "Epoch 1/50; Iter 14145/16384; Loss: 0.3082; Acc: 0.771; True Pos: 0.779; True Neg: 0.791\n",
            "Epoch 1/50; Iter 14209/16384; Loss: 0.3496; Acc: 0.771; True Pos: 0.780; True Neg: 0.791\n",
            "Epoch 1/50; Iter 14273/16384; Loss: 0.2842; Acc: 0.772; True Pos: 0.780; True Neg: 0.791\n",
            "Epoch 1/50; Iter 14337/16384; Loss: 0.3523; Acc: 0.772; True Pos: 0.780; True Neg: 0.791\n",
            "Epoch 1/50; Iter 14401/16384; Loss: 0.1674; Acc: 0.772; True Pos: 0.780; True Neg: 0.791\n",
            "Epoch 1/50; Iter 14465/16384; Loss: 0.4096; Acc: 0.772; True Pos: 0.781; True Neg: 0.792\n",
            "Epoch 1/50; Iter 14529/16384; Loss: 0.2892; Acc: 0.772; True Pos: 0.781; True Neg: 0.792\n",
            "Epoch 1/50; Iter 14593/16384; Loss: 0.2489; Acc: 0.773; True Pos: 0.781; True Neg: 0.792\n",
            "Epoch 1/50; Iter 14657/16384; Loss: 0.2490; Acc: 0.773; True Pos: 0.781; True Neg: 0.792\n",
            "Epoch 1/50; Iter 14721/16384; Loss: 0.4532; Acc: 0.773; True Pos: 0.782; True Neg: 0.792\n",
            "Epoch 1/50; Iter 14785/16384; Loss: 0.3586; Acc: 0.773; True Pos: 0.782; True Neg: 0.792\n",
            "Epoch 1/50; Iter 14849/16384; Loss: 0.3311; Acc: 0.773; True Pos: 0.782; True Neg: 0.793\n",
            "Epoch 1/50; Iter 14913/16384; Loss: 0.4451; Acc: 0.773; True Pos: 0.782; True Neg: 0.793\n",
            "Epoch 1/50; Iter 14977/16384; Loss: 0.6357; Acc: 0.774; True Pos: 0.782; True Neg: 0.793\n",
            "Epoch 1/50; Iter 15041/16384; Loss: 0.4666; Acc: 0.774; True Pos: 0.783; True Neg: 0.793\n",
            "Epoch 1/50; Iter 15105/16384; Loss: 0.3042; Acc: 0.774; True Pos: 0.783; True Neg: 0.793\n",
            "Epoch 1/50; Iter 15169/16384; Loss: 0.4418; Acc: 0.774; True Pos: 0.783; True Neg: 0.793\n",
            "Epoch 1/50; Iter 15233/16384; Loss: 0.2505; Acc: 0.774; True Pos: 0.783; True Neg: 0.794\n",
            "Epoch 1/50; Iter 15297/16384; Loss: 0.5144; Acc: 0.774; True Pos: 0.784; True Neg: 0.794\n",
            "Epoch 1/50; Iter 15361/16384; Loss: 0.3788; Acc: 0.775; True Pos: 0.784; True Neg: 0.794\n",
            "Epoch 1/50; Iter 15425/16384; Loss: 0.8657; Acc: 0.775; True Pos: 0.784; True Neg: 0.794\n",
            "Epoch 1/50; Iter 15489/16384; Loss: 0.4081; Acc: 0.775; True Pos: 0.784; True Neg: 0.794\n",
            "Epoch 1/50; Iter 15553/16384; Loss: 0.5732; Acc: 0.775; True Pos: 0.784; True Neg: 0.794\n",
            "Epoch 1/50; Iter 15617/16384; Loss: 0.4616; Acc: 0.775; True Pos: 0.784; True Neg: 0.794\n",
            "Epoch 1/50; Iter 15681/16384; Loss: 0.6900; Acc: 0.775; True Pos: 0.785; True Neg: 0.795\n",
            "Epoch 1/50; Iter 15745/16384; Loss: 0.8633; Acc: 0.776; True Pos: 0.785; True Neg: 0.795\n",
            "Epoch 1/50; Iter 15809/16384; Loss: 0.5322; Acc: 0.776; True Pos: 0.785; True Neg: 0.795\n",
            "Epoch 1/50; Iter 15873/16384; Loss: 0.1959; Acc: 0.776; True Pos: 0.785; True Neg: 0.795\n",
            "Epoch 1/50; Iter 15937/16384; Loss: 0.9084; Acc: 0.776; True Pos: 0.785; True Neg: 0.795\n",
            "Epoch 1/50; Iter 16001/16384; Loss: 0.4074; Acc: 0.776; True Pos: 0.786; True Neg: 0.795\n",
            "Epoch 1/50; Iter 16065/16384; Loss: 0.4039; Acc: 0.776; True Pos: 0.786; True Neg: 0.795\n",
            "Epoch 1/50; Iter 16129/16384; Loss: 0.8589; Acc: 0.777; True Pos: 0.786; True Neg: 0.796\n",
            "Epoch 1/50; Iter 16193/16384; Loss: 0.4017; Acc: 0.777; True Pos: 0.786; True Neg: 0.796\n",
            "Epoch 1/50; Iter 16257/16384; Loss: 0.6738; Acc: 0.777; True Pos: 0.786; True Neg: 0.796\n",
            "Epoch 1/50; Iter 16321/16384; Loss: 0.3713; Acc: 0.777; True Pos: 0.787; True Neg: 0.796\n",
            "Epoch 1/50; Avg. Train Loss: 0.4759; Train Acc: 0.777; Train TPR: 0.787; Train TNR: 0.796; Epoch Time: 52.95 mins; \n",
            "Avg. Dev Loss: 0.4432; Dev Acc: 0.812; Dev TPR: 0.700; Dev TNR: 1.000\n",
            "\n",
            "Dev loss decreased (inf --> 0.443162).  Saving model ...\n",
            "Checkpoint Directory does not exist! Making directory checkpoint\n",
            "Epoch 2/50; Iter 1/16384; Loss: 0.2955; Acc: 0.875; True Pos: 1.000; True Neg: 0.750\n",
            "Epoch 2/50; Iter 65/16384; Loss: 0.2914; Acc: 0.808; True Pos: 0.839; True Neg: 0.803\n",
            "Epoch 2/50; Iter 129/16384; Loss: 0.4702; Acc: 0.806; True Pos: 0.828; True Neg: 0.814\n",
            "Epoch 2/50; Iter 193/16384; Loss: 0.3039; Acc: 0.814; True Pos: 0.831; True Neg: 0.827\n",
            "Epoch 2/50; Iter 257/16384; Loss: 0.4423; Acc: 0.813; True Pos: 0.834; True Neg: 0.822\n",
            "Epoch 2/50; Iter 321/16384; Loss: 0.2583; Acc: 0.814; True Pos: 0.833; True Neg: 0.823\n",
            "Epoch 2/50; Iter 385/16384; Loss: 0.3002; Acc: 0.812; True Pos: 0.831; True Neg: 0.824\n",
            "Epoch 2/50; Iter 449/16384; Loss: 0.4821; Acc: 0.814; True Pos: 0.834; True Neg: 0.826\n",
            "Epoch 2/50; Iter 513/16384; Loss: 0.3222; Acc: 0.816; True Pos: 0.834; True Neg: 0.830\n",
            "Epoch 2/50; Iter 577/16384; Loss: 0.2702; Acc: 0.815; True Pos: 0.829; True Neg: 0.834\n",
            "Epoch 2/50; Iter 641/16384; Loss: 0.2338; Acc: 0.815; True Pos: 0.828; True Neg: 0.835\n",
            "Epoch 2/50; Iter 705/16384; Loss: 1.0807; Acc: 0.816; True Pos: 0.829; True Neg: 0.835\n",
            "Epoch 2/50; Iter 769/16384; Loss: 0.2666; Acc: 0.816; True Pos: 0.830; True Neg: 0.836\n",
            "Epoch 2/50; Iter 833/16384; Loss: 0.6280; Acc: 0.817; True Pos: 0.830; True Neg: 0.835\n",
            "Epoch 2/50; Iter 897/16384; Loss: 0.4267; Acc: 0.818; True Pos: 0.832; True Neg: 0.836\n",
            "Epoch 2/50; Iter 961/16384; Loss: 0.3374; Acc: 0.819; True Pos: 0.833; True Neg: 0.837\n",
            "Epoch 2/50; Iter 1025/16384; Loss: 0.4965; Acc: 0.819; True Pos: 0.836; True Neg: 0.834\n",
            "Epoch 2/50; Iter 1089/16384; Loss: 0.4458; Acc: 0.818; True Pos: 0.835; True Neg: 0.835\n",
            "Epoch 2/50; Iter 1153/16384; Loss: 0.4728; Acc: 0.820; True Pos: 0.837; True Neg: 0.835\n",
            "Epoch 2/50; Iter 1217/16384; Loss: 0.3106; Acc: 0.821; True Pos: 0.837; True Neg: 0.836\n",
            "Epoch 2/50; Iter 1281/16384; Loss: 0.5313; Acc: 0.821; True Pos: 0.838; True Neg: 0.836\n",
            "Epoch 2/50; Iter 1345/16384; Loss: 0.5461; Acc: 0.822; True Pos: 0.838; True Neg: 0.837\n",
            "Epoch 2/50; Iter 1409/16384; Loss: 0.6973; Acc: 0.821; True Pos: 0.837; True Neg: 0.836\n",
            "Epoch 2/50; Iter 1473/16384; Loss: 0.3355; Acc: 0.822; True Pos: 0.837; True Neg: 0.837\n",
            "Epoch 2/50; Iter 1537/16384; Loss: 0.7014; Acc: 0.822; True Pos: 0.836; True Neg: 0.838\n",
            "Epoch 2/50; Iter 1601/16384; Loss: 0.5510; Acc: 0.822; True Pos: 0.837; True Neg: 0.838\n",
            "Epoch 2/50; Iter 1665/16384; Loss: 0.1609; Acc: 0.823; True Pos: 0.838; True Neg: 0.837\n",
            "Epoch 2/50; Iter 1729/16384; Loss: 0.2703; Acc: 0.823; True Pos: 0.838; True Neg: 0.837\n",
            "Epoch 2/50; Iter 1793/16384; Loss: 0.4722; Acc: 0.823; True Pos: 0.839; True Neg: 0.838\n",
            "Epoch 2/50; Iter 1857/16384; Loss: 0.6921; Acc: 0.823; True Pos: 0.839; True Neg: 0.838\n",
            "Epoch 2/50; Iter 1921/16384; Loss: 0.4198; Acc: 0.824; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 1985/16384; Loss: 0.2596; Acc: 0.824; True Pos: 0.840; True Neg: 0.838\n",
            "Epoch 2/50; Iter 2049/16384; Loss: 0.4000; Acc: 0.825; True Pos: 0.841; True Neg: 0.839\n",
            "Epoch 2/50; Iter 2113/16384; Loss: 0.3400; Acc: 0.825; True Pos: 0.840; True Neg: 0.839\n",
            "Epoch 2/50; Iter 2177/16384; Loss: 0.2717; Acc: 0.825; True Pos: 0.840; True Neg: 0.839\n",
            "Epoch 2/50; Iter 2241/16384; Loss: 0.3340; Acc: 0.825; True Pos: 0.841; True Neg: 0.839\n",
            "Epoch 2/50; Iter 2305/16384; Loss: 0.4223; Acc: 0.824; True Pos: 0.840; True Neg: 0.838\n",
            "Epoch 2/50; Iter 2369/16384; Loss: 0.4506; Acc: 0.824; True Pos: 0.841; True Neg: 0.838\n",
            "Epoch 2/50; Iter 2433/16384; Loss: 0.4971; Acc: 0.824; True Pos: 0.841; True Neg: 0.838\n",
            "Epoch 2/50; Iter 2497/16384; Loss: 0.3914; Acc: 0.824; True Pos: 0.840; True Neg: 0.838\n",
            "Epoch 2/50; Iter 2561/16384; Loss: 0.3503; Acc: 0.824; True Pos: 0.840; True Neg: 0.838\n",
            "Epoch 2/50; Iter 2625/16384; Loss: 0.3738; Acc: 0.823; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 2689/16384; Loss: 0.4148; Acc: 0.823; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 2753/16384; Loss: 0.3291; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 2817/16384; Loss: 0.2163; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 2881/16384; Loss: 0.2970; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 2945/16384; Loss: 0.3641; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3009/16384; Loss: 0.3505; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3073/16384; Loss: 0.4847; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3137/16384; Loss: 0.3287; Acc: 0.822; True Pos: 0.838; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3201/16384; Loss: 0.4076; Acc: 0.822; True Pos: 0.838; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3265/16384; Loss: 0.3304; Acc: 0.823; True Pos: 0.838; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3329/16384; Loss: 0.3904; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3393/16384; Loss: 0.4107; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3457/16384; Loss: 0.3156; Acc: 0.823; True Pos: 0.838; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3521/16384; Loss: 0.4876; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3585/16384; Loss: 0.3899; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3649/16384; Loss: 0.5593; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3713/16384; Loss: 0.2890; Acc: 0.823; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3777/16384; Loss: 0.5169; Acc: 0.823; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3841/16384; Loss: 0.6788; Acc: 0.823; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3905/16384; Loss: 0.5814; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 3969/16384; Loss: 0.3477; Acc: 0.823; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 4033/16384; Loss: 0.1585; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 4097/16384; Loss: 0.5451; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 4161/16384; Loss: 0.2902; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 4225/16384; Loss: 0.2461; Acc: 0.823; True Pos: 0.838; True Neg: 0.837\n",
            "Epoch 2/50; Iter 4289/16384; Loss: 0.7670; Acc: 0.823; True Pos: 0.838; True Neg: 0.837\n",
            "Epoch 2/50; Iter 4353/16384; Loss: 0.5935; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 4417/16384; Loss: 0.4386; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 4481/16384; Loss: 0.7503; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 4545/16384; Loss: 0.5901; Acc: 0.823; True Pos: 0.838; True Neg: 0.837\n",
            "Epoch 2/50; Iter 4609/16384; Loss: 0.4537; Acc: 0.822; True Pos: 0.838; True Neg: 0.837\n",
            "Epoch 2/50; Iter 4673/16384; Loss: 0.4131; Acc: 0.822; True Pos: 0.838; True Neg: 0.837\n",
            "Epoch 2/50; Iter 4737/16384; Loss: 0.4236; Acc: 0.822; True Pos: 0.839; True Neg: 0.836\n",
            "Epoch 2/50; Iter 4801/16384; Loss: 0.2584; Acc: 0.822; True Pos: 0.838; True Neg: 0.836\n",
            "Epoch 2/50; Iter 4865/16384; Loss: 0.3513; Acc: 0.822; True Pos: 0.838; True Neg: 0.836\n",
            "Epoch 2/50; Iter 4929/16384; Loss: 0.3592; Acc: 0.822; True Pos: 0.839; True Neg: 0.836\n",
            "Epoch 2/50; Iter 4993/16384; Loss: 0.3781; Acc: 0.822; True Pos: 0.839; True Neg: 0.836\n",
            "Epoch 2/50; Iter 5057/16384; Loss: 0.4798; Acc: 0.822; True Pos: 0.839; True Neg: 0.836\n",
            "Epoch 2/50; Iter 5121/16384; Loss: 0.3059; Acc: 0.822; True Pos: 0.839; True Neg: 0.835\n",
            "Epoch 2/50; Iter 5185/16384; Loss: 0.3946; Acc: 0.822; True Pos: 0.839; True Neg: 0.835\n",
            "Epoch 2/50; Iter 5249/16384; Loss: 0.3706; Acc: 0.822; True Pos: 0.839; True Neg: 0.835\n",
            "Epoch 2/50; Iter 5313/16384; Loss: 0.7897; Acc: 0.822; True Pos: 0.839; True Neg: 0.836\n",
            "Epoch 2/50; Iter 5377/16384; Loss: 0.5538; Acc: 0.822; True Pos: 0.839; True Neg: 0.835\n",
            "Epoch 2/50; Iter 5441/16384; Loss: 0.4672; Acc: 0.822; True Pos: 0.839; True Neg: 0.836\n",
            "Epoch 2/50; Iter 5505/16384; Loss: 0.1953; Acc: 0.822; True Pos: 0.839; True Neg: 0.835\n",
            "Epoch 2/50; Iter 5569/16384; Loss: 0.2584; Acc: 0.822; True Pos: 0.840; True Neg: 0.836\n",
            "Epoch 2/50; Iter 5633/16384; Loss: 0.4031; Acc: 0.822; True Pos: 0.839; True Neg: 0.836\n",
            "Epoch 2/50; Iter 5697/16384; Loss: 0.3879; Acc: 0.823; True Pos: 0.840; True Neg: 0.836\n",
            "Epoch 2/50; Iter 5761/16384; Loss: 0.3468; Acc: 0.823; True Pos: 0.840; True Neg: 0.836\n",
            "Epoch 2/50; Iter 5825/16384; Loss: 0.4358; Acc: 0.822; True Pos: 0.839; True Neg: 0.836\n",
            "Epoch 2/50; Iter 5889/16384; Loss: 0.1909; Acc: 0.823; True Pos: 0.839; True Neg: 0.837\n",
            "Epoch 2/50; Iter 5953/16384; Loss: 0.8811; Acc: 0.823; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6017/16384; Loss: 0.4497; Acc: 0.823; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6081/16384; Loss: 0.2485; Acc: 0.823; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6145/16384; Loss: 0.3003; Acc: 0.823; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6209/16384; Loss: 0.4045; Acc: 0.823; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6273/16384; Loss: 0.4351; Acc: 0.823; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6337/16384; Loss: 0.2962; Acc: 0.823; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6401/16384; Loss: 0.3469; Acc: 0.824; True Pos: 0.840; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6465/16384; Loss: 0.3322; Acc: 0.824; True Pos: 0.841; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6529/16384; Loss: 0.5350; Acc: 0.824; True Pos: 0.841; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6593/16384; Loss: 0.2436; Acc: 0.823; True Pos: 0.841; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6657/16384; Loss: 0.2382; Acc: 0.824; True Pos: 0.841; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6721/16384; Loss: 0.6701; Acc: 0.824; True Pos: 0.841; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6785/16384; Loss: 0.5908; Acc: 0.823; True Pos: 0.841; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6849/16384; Loss: 0.4132; Acc: 0.824; True Pos: 0.841; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6913/16384; Loss: 0.2539; Acc: 0.824; True Pos: 0.841; True Neg: 0.837\n",
            "Epoch 2/50; Iter 6977/16384; Loss: 0.1899; Acc: 0.824; True Pos: 0.841; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7041/16384; Loss: 0.5237; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7105/16384; Loss: 0.6295; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7169/16384; Loss: 0.4909; Acc: 0.824; True Pos: 0.841; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7233/16384; Loss: 0.3733; Acc: 0.824; True Pos: 0.841; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7297/16384; Loss: 0.2931; Acc: 0.824; True Pos: 0.841; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7361/16384; Loss: 0.6952; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7425/16384; Loss: 0.3372; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7489/16384; Loss: 0.3206; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7553/16384; Loss: 0.2090; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7617/16384; Loss: 0.2843; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7681/16384; Loss: 0.3358; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7745/16384; Loss: 0.4139; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7809/16384; Loss: 0.3593; Acc: 0.824; True Pos: 0.842; True Neg: 0.838\n",
            "Epoch 2/50; Iter 7873/16384; Loss: 0.5729; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 7937/16384; Loss: 0.2978; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8001/16384; Loss: 0.3739; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8065/16384; Loss: 0.1991; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8129/16384; Loss: 0.3965; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8193/16384; Loss: 0.4810; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8257/16384; Loss: 0.2634; Acc: 0.825; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8321/16384; Loss: 0.4138; Acc: 0.824; True Pos: 0.842; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8385/16384; Loss: 0.3375; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8449/16384; Loss: 0.6306; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8513/16384; Loss: 0.2277; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8577/16384; Loss: 0.5010; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8641/16384; Loss: 0.2669; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8705/16384; Loss: 0.4109; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8769/16384; Loss: 0.4074; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8833/16384; Loss: 0.5472; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8897/16384; Loss: 0.3798; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 8961/16384; Loss: 0.2699; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 9025/16384; Loss: 0.3800; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 9089/16384; Loss: 0.3328; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 9153/16384; Loss: 0.4156; Acc: 0.825; True Pos: 0.843; True Neg: 0.838\n",
            "Epoch 2/50; Iter 9217/16384; Loss: 0.3430; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 9281/16384; Loss: 0.7919; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 9345/16384; Loss: 1.0403; Acc: 0.825; True Pos: 0.843; True Neg: 0.838\n",
            "Epoch 2/50; Iter 9409/16384; Loss: 0.2731; Acc: 0.825; True Pos: 0.843; True Neg: 0.838\n",
            "Epoch 2/50; Iter 9473/16384; Loss: 0.3853; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 9537/16384; Loss: 0.3573; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 9601/16384; Loss: 0.4724; Acc: 0.825; True Pos: 0.843; True Neg: 0.838\n",
            "Epoch 2/50; Iter 9665/16384; Loss: 0.2318; Acc: 0.825; True Pos: 0.843; True Neg: 0.837\n",
            "Epoch 2/50; Iter 9729/16384; Loss: 0.3501; Acc: 0.825; True Pos: 0.843; True Neg: 0.838\n",
            "Epoch 2/50; Iter 9793/16384; Loss: 0.4235; Acc: 0.825; True Pos: 0.844; True Neg: 0.837\n",
            "Epoch 2/50; Iter 9857/16384; Loss: 0.1770; Acc: 0.825; True Pos: 0.844; True Neg: 0.837\n",
            "Epoch 2/50; Iter 9921/16384; Loss: 0.4611; Acc: 0.825; True Pos: 0.844; True Neg: 0.837\n",
            "Epoch 2/50; Iter 9985/16384; Loss: 0.2754; Acc: 0.825; True Pos: 0.844; True Neg: 0.837\n",
            "Epoch 2/50; Iter 10049/16384; Loss: 0.4046; Acc: 0.826; True Pos: 0.844; True Neg: 0.837\n",
            "Epoch 2/50; Iter 10113/16384; Loss: 0.2817; Acc: 0.826; True Pos: 0.844; True Neg: 0.837\n",
            "Epoch 2/50; Iter 10177/16384; Loss: 0.2459; Acc: 0.826; True Pos: 0.844; True Neg: 0.838\n",
            "Epoch 2/50; Iter 10241/16384; Loss: 0.9357; Acc: 0.826; True Pos: 0.844; True Neg: 0.838\n",
            "Epoch 2/50; Iter 10305/16384; Loss: 0.6102; Acc: 0.826; True Pos: 0.844; True Neg: 0.837\n",
            "Epoch 2/50; Iter 10369/16384; Loss: 0.4064; Acc: 0.826; True Pos: 0.844; True Neg: 0.837\n",
            "Epoch 2/50; Iter 10433/16384; Loss: 0.3850; Acc: 0.826; True Pos: 0.844; True Neg: 0.837\n",
            "Epoch 2/50; Iter 10497/16384; Loss: 0.6051; Acc: 0.826; True Pos: 0.844; True Neg: 0.837\n",
            "Epoch 2/50; Iter 10561/16384; Loss: 0.3252; Acc: 0.826; True Pos: 0.844; True Neg: 0.838\n",
            "Epoch 2/50; Iter 10625/16384; Loss: 0.3620; Acc: 0.826; True Pos: 0.844; True Neg: 0.838\n",
            "Epoch 2/50; Iter 10689/16384; Loss: 0.5939; Acc: 0.826; True Pos: 0.844; True Neg: 0.838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50; Iter 10753/16384; Loss: 0.2802; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 10817/16384; Loss: 0.2793; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 10881/16384; Loss: 0.4042; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 10945/16384; Loss: 0.6075; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11009/16384; Loss: 0.3055; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11073/16384; Loss: 0.4908; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11137/16384; Loss: 0.2076; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11201/16384; Loss: 0.9127; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11265/16384; Loss: 0.3751; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11329/16384; Loss: 0.3236; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11393/16384; Loss: 0.1906; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11457/16384; Loss: 0.5750; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11521/16384; Loss: 0.2717; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11585/16384; Loss: 0.4929; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11649/16384; Loss: 0.5091; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11713/16384; Loss: 0.8500; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11777/16384; Loss: 0.5143; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11841/16384; Loss: 0.5550; Acc: 0.826; True Pos: 0.844; True Neg: nan\n",
            "Epoch 2/50; Iter 11905/16384; Loss: 0.2403; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 11969/16384; Loss: 0.2635; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12033/16384; Loss: 0.3768; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12097/16384; Loss: 0.6444; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12161/16384; Loss: 0.4578; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12225/16384; Loss: 0.2614; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12289/16384; Loss: 0.3567; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12353/16384; Loss: 0.3075; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12417/16384; Loss: 0.2989; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12481/16384; Loss: 0.2837; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12545/16384; Loss: 0.3776; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12609/16384; Loss: 0.2546; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12673/16384; Loss: 0.2832; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12737/16384; Loss: 0.3410; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12801/16384; Loss: 0.2914; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12865/16384; Loss: 0.3353; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12929/16384; Loss: 1.0619; Acc: 0.827; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 12993/16384; Loss: 0.2433; Acc: 0.827; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 13057/16384; Loss: 0.3058; Acc: 0.827; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 13121/16384; Loss: 0.3044; Acc: 0.826; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 13185/16384; Loss: 0.4274; Acc: 0.827; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 13249/16384; Loss: 0.3196; Acc: 0.827; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 13313/16384; Loss: 0.3536; Acc: 0.827; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 13377/16384; Loss: 0.1850; Acc: 0.827; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 13441/16384; Loss: 0.4491; Acc: 0.827; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 13505/16384; Loss: 0.1982; Acc: 0.827; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 13569/16384; Loss: 0.2134; Acc: 0.827; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 13633/16384; Loss: 0.2876; Acc: 0.827; True Pos: 0.845; True Neg: nan\n",
            "Epoch 2/50; Iter 13697/16384; Loss: 0.3609; Acc: 0.827; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 13761/16384; Loss: 0.2609; Acc: 0.827; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 13825/16384; Loss: 0.5735; Acc: 0.827; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 13889/16384; Loss: 0.7059; Acc: 0.827; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 13953/16384; Loss: 0.3874; Acc: 0.827; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14017/16384; Loss: 0.2506; Acc: 0.827; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14081/16384; Loss: 0.3346; Acc: 0.827; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14145/16384; Loss: 0.2906; Acc: 0.827; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14209/16384; Loss: 0.2951; Acc: 0.827; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14273/16384; Loss: 0.5501; Acc: 0.828; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14337/16384; Loss: 0.4778; Acc: 0.828; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14401/16384; Loss: 0.4178; Acc: 0.828; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14465/16384; Loss: 0.3743; Acc: 0.828; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14529/16384; Loss: 0.3831; Acc: 0.828; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14593/16384; Loss: 0.4885; Acc: 0.828; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14657/16384; Loss: 0.4212; Acc: 0.828; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14721/16384; Loss: 0.3440; Acc: 0.828; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14785/16384; Loss: 0.3130; Acc: 0.828; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14849/16384; Loss: 0.3414; Acc: 0.828; True Pos: 0.846; True Neg: nan\n",
            "Epoch 2/50; Iter 14913/16384; Loss: 0.2777; Acc: 0.828; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 14977/16384; Loss: 0.2861; Acc: 0.828; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15041/16384; Loss: 0.2121; Acc: 0.828; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15105/16384; Loss: 0.1991; Acc: 0.828; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15169/16384; Loss: 0.3224; Acc: 0.828; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15233/16384; Loss: 0.3737; Acc: 0.828; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15297/16384; Loss: 0.4731; Acc: 0.828; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15361/16384; Loss: 0.2668; Acc: 0.828; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15425/16384; Loss: 0.3674; Acc: 0.828; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15489/16384; Loss: 0.1464; Acc: 0.828; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15553/16384; Loss: 0.2902; Acc: 0.828; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15617/16384; Loss: 0.1969; Acc: 0.828; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15681/16384; Loss: 0.2454; Acc: 0.828; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15745/16384; Loss: 0.3218; Acc: 0.829; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15809/16384; Loss: 0.2974; Acc: 0.829; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15873/16384; Loss: 0.6487; Acc: 0.829; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 15937/16384; Loss: 0.3976; Acc: 0.829; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 16001/16384; Loss: 0.3648; Acc: 0.829; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 16065/16384; Loss: 0.2145; Acc: 0.829; True Pos: 0.847; True Neg: nan\n",
            "Epoch 2/50; Iter 16129/16384; Loss: 0.5012; Acc: 0.829; True Pos: 0.848; True Neg: nan\n",
            "Epoch 2/50; Iter 16193/16384; Loss: 0.2766; Acc: 0.829; True Pos: 0.848; True Neg: nan\n",
            "Epoch 2/50; Iter 16257/16384; Loss: 0.2379; Acc: 0.829; True Pos: 0.848; True Neg: nan\n",
            "Epoch 2/50; Iter 16321/16384; Loss: 0.8914; Acc: 0.829; True Pos: 0.848; True Neg: nan\n",
            "Epoch 2/50; Avg. Train Loss: 0.3970; Train Acc: 0.829; Train TPR: 0.848; Train TNR: nan; Epoch Time: 54.26 mins; \n",
            "Avg. Dev Loss: 0.5012; Dev Acc: 0.750; Dev TPR: 0.500; Dev TNR: 0.900\n",
            "\n",
            "1 epochs of increasing dev loss (0.443162 --> 0.501153).\n",
            "Epoch 3/50; Iter 1/16384; Loss: 0.3262; Acc: 0.812; True Pos: 0.727; True Neg: 1.000\n",
            "Epoch 3/50; Iter 65/16384; Loss: 0.4189; Acc: 0.831; True Pos: 0.867; True Neg: 0.826\n",
            "Epoch 3/50; Iter 129/16384; Loss: 0.2509; Acc: 0.831; True Pos: 0.853; True Neg: 0.837\n",
            "Epoch 3/50; Iter 193/16384; Loss: 0.1618; Acc: 0.839; True Pos: 0.860; True Neg: 0.846\n",
            "Epoch 3/50; Iter 257/16384; Loss: 0.4855; Acc: 0.839; True Pos: 0.857; True Neg: 0.848\n",
            "Epoch 3/50; Iter 321/16384; Loss: 0.6193; Acc: 0.841; True Pos: 0.862; True Neg: 0.846\n",
            "Epoch 3/50; Iter 385/16384; Loss: 0.3656; Acc: 0.841; True Pos: 0.862; True Neg: 0.848\n",
            "Epoch 3/50; Iter 449/16384; Loss: 0.5900; Acc: 0.839; True Pos: 0.859; True Neg: 0.847\n",
            "Epoch 3/50; Iter 513/16384; Loss: 0.4836; Acc: 0.836; True Pos: 0.856; True Neg: 0.844\n",
            "Epoch 3/50; Iter 577/16384; Loss: 0.2310; Acc: 0.838; True Pos: 0.856; True Neg: 0.849\n",
            "Epoch 3/50; Iter 641/16384; Loss: 0.3392; Acc: 0.838; True Pos: 0.856; True Neg: 0.849\n",
            "Epoch 3/50; Iter 705/16384; Loss: 0.4766; Acc: 0.839; True Pos: 0.856; True Neg: 0.851\n",
            "Epoch 3/50; Iter 769/16384; Loss: 0.1904; Acc: 0.838; True Pos: 0.855; True Neg: 0.849\n",
            "Epoch 3/50; Iter 833/16384; Loss: 0.2901; Acc: 0.838; True Pos: 0.854; True Neg: 0.851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8upeaUiiZ0u4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}