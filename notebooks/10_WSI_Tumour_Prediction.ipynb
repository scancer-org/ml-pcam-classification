{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WSI Tumour Prediction",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1cB2w_muAFPSVcZqiSOnOdA0yMsvqWWgf",
      "authorship_tag": "ABX9TyPrMf+UeZo/kMVpC5zmQ7ln",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scancer-org/ml-pcam-classification/blob/main/notebooks/10_WSI_Tumour_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSbw12tVs0cZ"
      },
      "source": [
        "# Step Plan\n",
        "\n",
        "- [x] Setup all the requirements for the code\n",
        "- [x] Load a Google Drive that has symbolic links to the Camleyon16 dataset\n",
        "- [x] Load a sample file\n",
        "- [x] Get a sliding window and padding parameters\n",
        "- [x] Pad the WSI\n",
        "- [x] Segment the tissue (and create a mask)\n",
        "- [x] Load up the PCam model from the stored weights\n",
        "- [x] Predict tumour regions\n",
        "- [x] Colourise the regions and save\n",
        "- [x] Try to size tensors so it doesn't crash running out of memory\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIUBBbhnFsy8"
      },
      "source": [
        "!wget -nc -q https://github.com/computationalpathologygroup/ASAP/releases/download/1.9/ASAP-1.9-Linux-Ubuntu1804.deb\n",
        "!sudo apt-get -qq -y install ./ASAP-1.9-Linux-Ubuntu1804.deb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjmALrK0SFy3"
      },
      "source": [
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.cm as cm\n",
        "from skimage.filters import gaussian\n",
        "from xml.etree import ElementTree as ET\n",
        "from PIL import Image, ImageDraw\n",
        "from skimage.color import rgb2hsv\n",
        "from skimage.transform import resize\n",
        "from google.colab import drive\n",
        "import gc\n",
        "import sys\n",
        "sys.path.append(r'/opt/ASAP/bin')\n",
        "try:\n",
        "    import multiresolutionimageinterface as mir\n",
        "except ImportError:\n",
        "    print(\"ASAP package not installed.\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF8Es8kc3iKu"
      },
      "source": [
        "# WSI_FILE = \"/content/drive/MyDrive/FSDL Project/CAMELYON16/training/tumor/tumor_029.tif\"\n",
        "WSI_FILE = \"/content/drive/MyDrive/FSDL Project/CAMELYON16/testing/images/test_001.tif\"\n",
        "WSI_LEVEL = 2 # Magnification 0=40x, 1=20x, 2=10x, ...\n",
        "PCAM_MODEL = \"/content/drive/MyDrive/FSDL Project/PCam/pcam_cnn_v1.2.pt\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/FSDL Project/\"\n",
        "WINDOW = (96, 96)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alREa4jV0bke",
        "outputId": "2572ce85-8408-4fc6-f2f9-46e8a047db40"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av3IamRd0dCM"
      },
      "source": [
        "class TIFReader:\n",
        "\n",
        "    def __init__(self, file, level):\n",
        "\n",
        "        self.file = file\n",
        "        self.reader = mir.MultiResolutionImageReader()\n",
        "        self.mr_image = self.reader.open(self.file)\n",
        "        self.level = level\n",
        "\n",
        "    def get_shape(self):\n",
        "        # X, Y\n",
        "        return self.mr_image.getLevelDimensions(self.level)\n",
        "\n",
        "    def load_patch(self, x, y, width, height):\n",
        "        ds = self.mr_image.getLevelDownsample(self.level)\n",
        "        image_patch = self.mr_image.getUCharPatch(int(x * ds), int(y * ds), width, height, self.level)\n",
        "        return image_patch\n",
        "\n",
        "    def load_image(self):\n",
        "        assert self.level >= 2\n",
        "        shape = self.get_shape()\n",
        "        # TODO: Remove this hack\n",
        "        width = shape[0]\n",
        "        height = shape[1]\n",
        "        return self.load_patch(0, height//2, width//2, height//2)\n",
        "        # return self.load_patch(0, 0, shape[0], shape[1])\n",
        "\n",
        "    @staticmethod\n",
        "    def segment_tissue(image):\n",
        "        resized = image[::16, ::16, :].copy()\n",
        "        hsv = rgb2hsv(resized)\n",
        "        return resize(hsv[:, :, 1], image.shape[:2], mode='constant', cval=0, anti_aliasing=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwNL9zHZBEK7"
      },
      "source": [
        "def sliding_window(image_shape, window_shape, stride=None):\n",
        "\n",
        "    if stride is None:\n",
        "        stride = (window_shape[0], window_shape[1])\n",
        "\n",
        "    # Padding\n",
        "    padding_x = 0 if image_shape[1] % window_shape[1] == 0 else window_shape[1] - image_shape[1] % window_shape[1]\n",
        "    padding_y = 0 if image_shape[0] % window_shape[0] == 0 else window_shape[0] - image_shape[0] % window_shape[0]\n",
        "    padded_shape = (image_shape[0] + padding_y, image_shape[1] + padding_x)\n",
        "\n",
        "    x = np.arange(0, padded_shape[1], stride[1])\n",
        "    y = np.arange(0, padded_shape[0], stride[0])\n",
        "\n",
        "    x1, y1 = np.meshgrid(x, y)\n",
        "\n",
        "    x2 = x1 + window_shape[1]\n",
        "    y2 = y1 + window_shape[0]\n",
        "\n",
        "    return np.stack([x1, y1, x2, y2], axis=2), {'x': padding_x, 'y': padding_y}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZodlC3HE3FO"
      },
      "source": [
        "def predict_tumor_regions(wsi, tissue_mask, windows):\n",
        "\n",
        "    model = torch.jit.load(PCAM_MODEL)\n",
        "    device = torch.device(\"cuda\")\n",
        "    model.eval()\n",
        "  \n",
        "    # Initialize with zeros\n",
        "    tumor = np.zeros(wsi.shape[:2])\n",
        "\n",
        "    for i in range(windows.shape[0]):\n",
        "        for j in range(windows.shape[1]):\n",
        "\n",
        "            # [x1, y1, x2, y2]\n",
        "            bbox = windows[i, j, :].reshape(-1)\n",
        "\n",
        "            # Tissue mask patch\n",
        "            mask_patch = tissue_mask[bbox[1]:bbox[3], bbox[0]: bbox[2]]\n",
        "\n",
        "            if mask_patch.mean() > 0.075:\n",
        "\n",
        "                # Select patch from window\n",
        "                wsi_patch = np.expand_dims(wsi[bbox[1]:bbox[3], bbox[0]: bbox[2], :].copy(), axis=0)\n",
        "\n",
        "                # Convert to tensor\n",
        "                wsi_tensor = torch.from_numpy(wsi_patch).permute(0, 3, 1, 2).float().to(device) / 255.\n",
        "\n",
        "                # Inference\n",
        "                tumor[bbox[1]:bbox[3], bbox[0]:bbox[2]] = torch.sigmoid(model(wsi_tensor)).squeeze().item()\n",
        "\n",
        "    return gaussian(tumor, preserve_range=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZKYuxj55qck"
      },
      "source": [
        "reader = TIFReader(WSI_FILE, WSI_LEVEL)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cruqsnuz9wrA"
      },
      "source": [
        "wsi = reader.load_image()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcosV4sFAcRq"
      },
      "source": [
        "windows, padding = sliding_window(wsi.shape, WINDOW)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vb-Wj5QA0J1"
      },
      "source": [
        "wsi_padded = np.pad(wsi, ((0, padding['y']), (0, padding['x']), (0, 0)), mode='constant', constant_values=255)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZIGmCVbVWAx",
        "outputId": "ed284d03-b26f-4332-eb8a-e39a169c488e"
      },
      "source": [
        "del wsi\n",
        "gc.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "417"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN68IiMgBbCi"
      },
      "source": [
        "tissue_mask = reader.segment_tissue(wsi_padded)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-OXAFa1Ehz6"
      },
      "source": [
        "tumor_map = predict_tumor_regions(wsi_padded, tissue_mask, windows)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tjUuIZMVfJP",
        "outputId": "885df302-5a0b-4b5d-faac-9b0d84dc35cb"
      },
      "source": [
        "del reader\n",
        "del wsi_padded\n",
        "del tissue_mask\n",
        "del windows\n",
        "gc.collect()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrcTnpnETMt0"
      },
      "source": [
        "# np.save(OUTPUT_PATH + '/normal_116_2.npy', tumor_map)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvhzr3XnUiNy"
      },
      "source": [
        "cmapper = cm.get_cmap('plasma')\n",
        "colorized = Image.fromarray(np.uint8(cmapper(np.clip(tumor_map, 0, 1)) * 255))\n",
        "colorized.save(OUTPUT_PATH + '/test_001_4.png')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDBNzTRkE50J",
        "outputId": "e7115bd4-0041-410b-f3f0-1d4edef48658"
      },
      "source": [
        "del colorized\n",
        "gc.collect()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8ghFCMVNEiH"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}